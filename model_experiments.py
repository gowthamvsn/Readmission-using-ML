# -*- coding: utf-8 -*-
"""5502_readmission.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13WXkpMyDDjJqmXTEKBLubiOqgFQ1Td70
"""

# This is the final code. it has all models included. Use it to write the analysis report

 
# =============================================================================
# DIABETES: PREDICT ANY READMISSION AT ALL (<30 or >30 vs NO)
# =============================================================================

import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
import warnings; warnings.filterwarnings("ignore")
plt.rcParams.update({'font.size': 12})

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV

from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    average_precision_score, roc_curve, precision_recall_curve
)

# ------------------- RareCategoryGrouper -------------------
class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    def __init__(self, min_freq=50):
        self.min_freq = min_freq
        self.frequent_maps_ = {}
        self.columns_ = []

    def fit(self, X, y=None):
        X = pd.DataFrame(X)
        self.columns_ = X.columns.tolist()
        for c in self.columns_:
            vc = X[c].astype(str).value_counts(dropna=False)
            self.frequent_maps_[c] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        X = pd.DataFrame(X, columns=self.columns_) if not isinstance(X, pd.DataFrame) else X.copy()
        for c in self.columns_:
            keep = self.frequent_maps_[c]
            X[c] = X[c].astype(str).where(X[c].astype(str).isin(keep), "RARE")
        return X

# ------------------- Load & Preprocess -------------------
df = pd.read_csv("diabetic_data.csv", na_values="?", low_memory=False)
df = df[df.gender != "Unknown/Invalid"].copy()
df.drop(columns=["encounter_id", "patient_nbr", "weight", "payer_code", "examide", "citoglipton"],
        errors="ignore", inplace=True)

# TARGET: ANY READMISSION
df["readmitted_any"] = (df["readmitted"] != "NO").astype(int)
print(f"Dataset: {df.shape} | Any readmission rate: {df['readmitted_any'].mean():.1%}")

# Feature Engineering
def age_mid(x):
    m = re.match(r"\[(\d+)-(\d+)\)", str(x))
    return (int(m.group(1)) + int(m.group(2))) / 2 if m else np.nan
df["age_num"] = df["age"].apply(age_mid)

def bucket_icd9(code):
    if pd.isna(code): return "missing"
    s = str(code).strip()
    if s.startswith(("V","E")): return s[0].lower()
    try: v = float(s)
    except: return "other"
    if 390 <= v <= 459 or v == 785: return "circulatory"
    if 460 <= v <= 519 or v == 786: return "respiratory"
    if 520 <= v <= 579 or v == 787: return "digestive"
    if 250 <= v < 251: return "diabetes"
    if 800 <= v <= 999: return "injury"
    if 140 <= v <= 239: return "neoplasms"
    return "other"

for c in ["diag_1", "diag_2", "diag_3"]:
    df[f"{c}_bucket"] = df[c].apply(bucket_icd9)

df["max_glu_serum"] = df["max_glu_serum"].map({"None":0, "Norm":1, ">200":2, ">300":3}).fillna(0)
df["A1Cresult"] = df["A1Cresult"].map({"None":0, "Norm":1, ">7":2, ">8":3}).fillna(0)
df["race"] = df["race"].fillna("Other")
df["total_visits"] = df["number_outpatient"] + df["number_emergency"] + df["number_inpatient"]
df["meds_per_day"] = df["num_medications"] / (df["time_in_hospital"] + 1)

X = df.drop(columns=["readmitted", "readmitted_any", "age", "diag_1", "diag_2", "diag_3"])
y = df["readmitted_any"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ------------------- Preprocessing -------------------
num_cols = X.select_dtypes("number").columns.tolist()
cat_cols = X.select_dtypes("object").columns.tolist()

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median"))])
cat_pipe = Pipeline([
    ("rare", RareCategoryGrouper(min_freq=50)),
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

preprocess = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
], verbose_feature_names_out=False)

# ------------------- Models  -------------------
models = {
    "Random Forest": RandomForestClassifier(n_estimators=1000, max_features=0.4, n_jobs=-1, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=1000, max_depth=8, learning_rate=0.05, subsample=0.9,
                             colsample_bytree=0.9, random_state=42, n_jobs=-1),
    "LightGBM": LGBMClassifier(n_estimators=1000, max_depth=12, learning_rate=0.05, num_leaves=200,
                               subsample=0.9, colsample_bytree=0.9, random_state=42, verbose=-1),
    "Logistic Regression": LogisticRegression(max_iter=1000, n_jobs=-1),
    "Linear SVM": CalibratedClassifierCV(
        LinearSVC(class_weight="balanced", max_iter=20000), cv=3, method="sigmoid"
    )
}

# ------------------- Train & Large Beautiful Plots -------------------
results = []
n_models = len(models)
fig = plt.figure(figsize=(24, 10 * n_models))  # Very tall for spacing

plot_idx = 1
row = 0

for name, model in models.items():
    print(f"\n{'='*100}")
    print(f" TRAINING: {name.upper()}")
    print('='*100)

    pipe = Pipeline([("prep", preprocess), ("clf", model)])
    pipe.fit(X_train, y_train)

    pred = pipe.predict(X_test)
    prob = pipe.predict_proba(X_test)[:, 1]

    auc = roc_auc_score(y_test, prob)
    pr_auc = average_precision_score(y_test, prob)
    report = classification_report(y_test, pred, output_dict=True)
    cm = confusion_matrix(y_test, pred)

    results.append({
        "Model": name,
        "AUC": round(auc, 4),
        "PR-AUC": round(pr_auc, 4),
        "Recall": round(report["1"]["recall"], 4),
        "Precision": round(report["1"]["precision"], 4),
        "F1": round(report["1"]["f1-score"], 4),
        "TP": int(cm[1,1])
    })

    print(f"\nCLASSIFICATION REPORT — {name}")
    print(classification_report(y_test, pred, digits=4))
    print("Confusion Matrix:\n", cm)

    # Large, spaced plots
    # ROC Curve
    ax1 = fig.add_subplot(n_models, 3, plot_idx)
    fpr, tpr, _ = roc_curve(y_test, prob)
    ax1.plot(fpr, tpr, label=f'AUC = {auc:.4f}', lw=4, color="darkorange")
    ax1.plot([0,1],[0,1],'k--', lw=2)
    ax1.set_title(f"{name} — ROC Curve", fontsize=18, pad=20, fontweight="bold")
    ax1.set_xlabel("False Positive Rate", fontsize=14)
    ax1.set_ylabel("True Positive Rate", fontsize=14)
    ax1.legend(fontsize=14)
    ax1.grid(True, alpha=0.3)
    plot_idx += 1

    # PR Curve
    ax2 = fig.add_subplot(n_models, 3, plot_idx)
    prec, rec, _ = precision_recall_curve(y_test, prob)
    ax2.plot(rec, prec, label=f'PR-AUC = {pr_auc:.4f}', lw=4, color="green")
    ax2.set_title(f"{name} — Precision-Recall Curve", fontsize=18, pad=20, fontweight="bold")
    ax2.set_xlabel("Recall", fontsize=14)
    ax2.set_ylabel("Precision", fontsize=14)
    ax2.legend(fontsize=14)
    ax2.grid(True, alpha=0.3)
    plot_idx += 1

    # Confusion Matrix
    ax3 = fig.add_subplot(n_models, 3, plot_idx)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, annot_kws={"size": 20},
                xticklabels=["No Readmission", "Readmitted"],
                yticklabels=["No Readmission", "Readmitted"])
    ax3.set_title(f"{name} — Confusion Matrix", fontsize=18, pad=20, fontweight="bold")
    ax3.set_xlabel("Predicted", fontsize=14)
    ax3.set_ylabel("Actual", fontsize=14)
    plot_idx += 1

plt.suptitle("PREDICTING ANY DIABETES READMISSION ", fontsize=32, fontweight="bold", y=0.98)
plt.tight_layout(rect=[0, 0.03, 1, 0.95], h_pad=8.0, w_pad=6.0)
plt.show()

# ------------------- Final Ranking Table -------------------
results_df = pd.DataFrame(results).sort_values("AUC", ascending=False).reset_index(drop=True)
results_df.index += 1

print("\n" + "="*140)
print(" " * 55 + "FINAL RANKING")
print("="*140)
print(results_df.to_string(index=True))
print("="*140)

winner = results_df.iloc[0]
print(f"\nCHAMPION MODEL: {winner['Model']}")
print(f"         AUC            = {winner['AUC']:.4f}")
print(f"         Recall         = {winner['Recall']:.4f}  →  catches {winner['Recall']*100:.1f}% of ALL readmissions")
print(f"         F1-Score       = {winner['F1']:.4f}")
print(f"         True Positives = {winner['TP']:,}")

import joblib, os
from xgboost import XGBClassifier

final_model = Pipeline([
    ("prep", preprocess),
    ("clf", XGBClassifier(n_estimators=1000, max_depth=8, learning_rate=0.05,
                          subsample=0.9, colsample_bytree=0.9,
                          random_state=42, n_jobs=-1))
])

print("Training champion model (this takes ~20–30 seconds)...")
final_model.fit(X_train, y_train)
print("Model trained! Saving...")

# Save both the model and the column order
joblib.dump(final_model, "anyreadmit_champion_model.pkl")
joblib.dump(X.columns.tolist(), "anyreadmit_feature_columns.pkl")
print("Model saved as 'anyreadmit_champion_model.pkl'")

import joblib
import pandas as pd
import numpy as np
import re
from IPython.display import display, Markdown, clear_output
import ipywidgets as widgets

# Load model
model = joblib.load("anyreadmit_champion_model.pkl")
cols = joblib.load("anyreadmit_feature_columns.pkl")
print("Model loaded — live predictions ready!")

# Mapping for A1C and glu serum
a1c_map = {"None": 0, "Norm": 1, ">7": 2, ">8": 3}
glu_map = {"None": 0, "Norm": 1, ">200": 2, ">300": 3}

# Blank patient with safe defaults
def blank_patient():
    data = {}
    meds = ["metformin","repaglinide","nateglinide","chlorpropamide","glimepiride","glipizide",
            "glyburide","pioglitazone","rosiglitazone","acarbose","miglitol","insulin"]
    for c in cols:
        if any(m in c for m in meds): data[c] = "No"
        elif c in ["change","diabetesMed"]: data[c] = "No"
        elif "bucket" in c: data[c] = "missing"
        elif c in ["A1Cresult","max_glu_serum"]: data[c] = "None"
        elif c in ["age","gender","race","medical_specialty"]: data[c] = "Other"
        else: data[c] = 0
    return pd.DataFrame([data])[cols]

# UI
display(Markdown("# Live Readmission Risk Calculator"))
display(Markdown("**Enter patient details → instant clinical decision support**"))

age = widgets.Dropdown(options=["[0-10)","[10-20)","[20-30)","[30-40)","[40-50)","[50-60)","[60-70)","[70-80)","[80-90)","[90-100)"], value="[70-80)", description="Age:")
gender = widgets.Dropdown(options=["Male","Female"], value="Female", description="Gender:")
race = widgets.Dropdown(options=["Caucasian","AfricanAmerican","Hispanic","Asian","Other"], value="Caucasian", description="Race:")
days = widgets.IntSlider(min=1, max=14, value=4, description="Days in Hosp:")
labs = widgets.IntSlider(min=0, max=130, value=40, description="Lab Tests:")
meds_count = widgets.IntSlider(min=1, max=81, value=16, description="Medications:")
outp = widgets.IntSlider(min=0, max=40, value=0, description="Outpatient:")
er = widgets.IntSlider(min=0, max=76, value=0, description="ER Visits:")
inp = widgets.IntSlider(min=0, max=21, value=1, description="Inpatient Visits:")
diag = widgets.Text(value="250.83", description="Primary ICD9:")
a1c = widgets.Dropdown(options=["None","Norm",">7",">8"], value="None", description="A1C Result:")

button = widgets.Button(description="Predict Risk Now", button_style="success", layout=widgets.Layout(width="100%", height="70px"))
out = widgets.Output()

def predict_now(b):
    with out:
        clear_output()
        patient = blank_patient().copy()

        # Fill user data
        patient.loc[0, "age"] = age.value
        patient.loc[0, "gender"] = gender.value
        patient.loc[0, "race"] = race.value
        patient.loc[0, "time_in_hospital"] = days.value
        patient.loc[0, "num_lab_procedures"] = labs.value
        patient.loc[0, "num_medications"] = meds_count.value
        patient.loc[0, "number_outpatient"] = outp.value
        patient.loc[0, "number_emergency"] = er.value
        patient.loc[0, "number_inpatient"] = inp.value
        patient.loc[0, "diag_1"] = diag.value
        patient.loc[0, "A1Cresult"] = a1c.value

        patient["A1Cresult"] = patient["A1Cresult"].map(a1c_map)
        patient["max_glu_serum"] = patient["max_glu_serum"].map(glu_map)

        # Engineered features
        patient.loc[0, "total_visits"] = outp.value + er.value + inp.value
        patient.loc[0, "meds_per_day"] = meds_count.value / (days.value + 1)
        m = re.match(r"\[(\d+)-(\d+)\)", age.value)
        patient.loc[0, "age_num"] = (int(m.group(1)) + int(m.group(2))) / 2 if m else 50

        def icd_bucket(code):
            try: v = float(code);
            except: return "other"
            if 390<=v<=459 or v==785: return "circulatory"
            if 460<=v<=519 or v==786: return "respiratory"
            if 520<=v<=579 or v==787: return "digestive"
            if 250<=v<251: return "diabetes"
            if 800<=v<=999: return "injury"
            if 140<=v<=239: return "neoplasms"
            return "other"
        patient.loc[0, "diag_1_bucket"] = icd_bucket(diag.value)

        # Predict
        risk = model.predict_proba(patient)[0,1] * 100
        display(Markdown(f"## Readmission Risk: **{risk:.1f}%**"))
        if risk > 70:
            display(Markdown("<h2 style='color:red'>HIGH RISK – Urgent intervention required</h2>"))
        elif risk > 55:
            display(Markdown("<h2 style='color:orange'>MODERATE RISK – Schedule follow-up</h2>"))
        else:
            display(Markdown("<h2 style='color:green'>LOW RISK – Standard discharge plan</h2>"))

button.on_click(predict_now)
display(widgets.VBox([age,gender,race,days,labs,meds_count,outp,er,inp,diag,a1c,button,out]))

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('diabetic_data.csv', na_values='?')

"""# Preprocessing"""

data.shape

data.isnull().sum()

data.drop(columns=['weight' , 'max_glu_serum', 'A1Cresult','payer_code','encounter_id',	'patient_nbr'], inplace=True)

data.shape

data.isnull().sum()

data['race'] = data['race'].fillna('other')
data['medical_specialty'] = data['medical_specialty'].fillna('other')

data.shape

data.isnull().sum()

data_clean = data.dropna()

data_clean.shape

data_clean.isnull().sum()

data.dtypes

"""# Encoding"""

#Encoding
from sklearn.preprocessing import LabelEncoder


le = LabelEncoder()
data_clean['admission_type_id'] = le.fit_transform(data_clean['admission_type_id'])
data_clean['discharge_disposition_id'] = le.fit_transform(data_clean['discharge_disposition_id'])
data_clean['admission_source_id'] = le.fit_transform(data_clean['admission_source_id'])
data_clean['race'] = le.fit_transform(data_clean['race'])
data_clean['gender'] = le.fit_transform(data_clean['gender'])
data_clean['age'] = le.fit_transform(data_clean['age'])
data_clean['diag_1'] = le.fit_transform(data_clean['diag_1'])
data_clean['diag_2'] = le.fit_transform(data_clean['diag_2'])
data_clean['diag_3'] = le.fit_transform(data_clean['diag_3'])
data_clean['metformin'] = le.fit_transform(data_clean['metformin'])
data_clean['citoglipton'] = le.fit_transform(data_clean['metformin'])
data_clean['repaglinide'] = le.fit_transform(data_clean['repaglinide'])
data_clean['nateglinide'] = le.fit_transform(data_clean['nateglinide'])
data_clean['chlorpropamide'] = le.fit_transform(data_clean['chlorpropamide'])
data_clean['glimepiride'] = le.fit_transform(data_clean['glimepiride'])
data_clean['acetohexamide'] = le.fit_transform(data_clean['acetohexamide'])
data_clean['glipizide'] = le.fit_transform(data_clean['glipizide'])
data_clean['glyburide'] = le.fit_transform(data_clean['glyburide'])
data_clean['tolbutamide'] = le.fit_transform(data_clean['tolbutamide'])
data_clean['pioglitazone'] = le.fit_transform(data_clean['pioglitazone'])
data_clean['rosiglitazone'] = le.fit_transform(data_clean['rosiglitazone'])
data_clean['acarbose'] = le.fit_transform(data_clean['acarbose'])
data_clean['miglitol'] = le.fit_transform(data_clean['miglitol'])
data_clean['troglitazone'] = le.fit_transform(data_clean['troglitazone'])
data_clean['tolazamide'] = le.fit_transform(data_clean['tolazamide'])
data_clean['insulin'] = le.fit_transform(data_clean['insulin'])
data_clean['glyburide-metformin'] = le.fit_transform(data_clean['glyburide-metformin'])
data_clean['glipizide-metformin'] = le.fit_transform(data_clean['glipizide-metformin'])
data_clean['glimepiride-pioglitazone'] = le.fit_transform(data_clean['glimepiride-pioglitazone'])
data_clean['metformin-rosiglitazone'] = le.fit_transform(data_clean['metformin-rosiglitazone'])
data_clean['metformin-pioglitazone'] = le.fit_transform(data_clean['metformin-pioglitazone'])
data_clean['change'] = le.fit_transform(data_clean['change'])
data_clean['diabetesMed'] = le.fit_transform(data_clean['diabetesMed'])
data_clean['readmitted'] = le.fit_transform(data_clean['readmitted'])
data_clean['medical_specialty'] = le.fit_transform(data_clean['medical_specialty'])
data_clean['examide'] = le.fit_transform(data_clean['examide'])



#Transforming in a binary problem
# data_clean['readmitted'] = data_clean['readmitted'].apply(lambda x: 1 if x == '<30' else (2 if x == '>30' else 0))
data_clean.head(15)

data_clean['readmitted'].value_counts()

"""# Random Forest, Group Preprocessing"""

# Not the final code. ignore it

import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt, joblib
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Optional (installed in most environments)
try:
    from xgboost import XGBClassifier
    XGB_OK = True
except Exception:
    XGB_OK = False

# ----------------- Config -----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"    # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

# EXACT drops from your notebook
DROP_COLS = ['weight','max_glu_serum','A1Cresult','payer_code','encounter_id','patient_nbr']


# low_memory=False to avoid DtypeWarning & slow dtype guessing
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
assert 'readmitted' in df.columns, "readmitted target not found"

# drop columns exactly as you did
for c in DROP_COLS:
    if c in df.columns: df.drop(columns=c, inplace=True)

# fill 'race' and 'medical_specialty' with 'other' exactly like your notebook
for c in ['race','medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# target: any readmission (<30 or >30) vs NO  (same meaning as typical notebook)
y = (df['readmitted'].astype(str).str.upper() != 'NO').astype(int)
X = df.drop(columns=['readmitted']).copy()

# 1) age_num midpoint (keeps original 'age' categorical; models can use both)
def age_mid(a):
    m = re.match(r"\[(\d+)-(\d+)\)", str(a))
    return np.nan if not m else (int(m.group(1))+int(m.group(2)))/2
if 'age' in X.columns:
    X['age_num'] = X['age'].apply(age_mid)

# ----------------- Column sets -----------------
num_cols = [c for c in [
    'time_in_hospital','num_lab_procedures','num_procedures','num_medications',
    'number_outpatient','number_emergency','number_inpatient','number_diagnoses','age_num'
] if c in X.columns]

cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ----------------- Split -----------------
X_tr, X_te, y_tr, y_te = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)
pos_weight = (y_tr.shape[0] - y_tr.sum()) / max(1, y_tr.sum())

# - Numerics: median impute + scale (scale helps LR/SVM; trees ignore scale)
# - Categoricals: impute then OrdinalEncoder (LabelEncoder-like across columns)
num_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="median")),
    ("sc", StandardScaler()),
])

# For 'race' and 'medical_specialty', preserve your fill='other'
special_cat = [c for c in ['race','medical_specialty'] if c in cat_cols]
rest_cat = [c for c in cat_cols if c not in special_cat]

ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    dtype=np.int64
)

cat_special_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="constant", fill_value="other")),
    ("enc", ordinal_enc),
])

cat_rest_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("enc", ordinal_enc),
])

transformers = []
if num_cols: transformers.append(("num", num_pipe, num_cols))
if special_cat: transformers.append(("cat_special", cat_special_pipe, special_cat))
if rest_cat: transformers.append(("cat_rest", cat_rest_pipe, rest_cat))

preproc = ColumnTransformer(transformers=transformers, remainder="drop")

# ----------------- Models (no CV; sensible defaults) -----------------
models = {
    "logreg": Pipeline([
        ("prep", preproc),
        ("clf", LogisticRegression(
            max_iter=5000, solver="lbfgs", class_weight="balanced", C=1.0))
    ]),
    "rf": Pipeline([
        ("prep", preproc),
        ("clf", RandomForestClassifier(
            n_estimators=400, max_depth=None, min_samples_leaf=1,
            class_weight="balanced_subsample", random_state=SEED, n_jobs=-1))
    ]),
    "svm_rbf": Pipeline([
        ("prep", preproc),
        ("clf", SVC(
            kernel="rbf", probability=True, class_weight="balanced",
            C=1.0, gamma="scale", random_state=SEED))
    ]),
}

if XGB_OK:
    models["xgb"] = Pipeline([
        ("prep", preproc),
        ("clf", XGBClassifier(
            n_estimators=400, max_depth=4, learning_rate=0.05,
            subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,
            objective="binary:logistic", eval_metric="auc", random_state=SEED,
            tree_method="hist", scale_pos_weight=float(pos_weight)))
    ])

# Optional: to keep SVM snappy on big data, subsample its training split only
SVM_MAX = 30000
if "svm_rbf" in models and len(X_tr) > SVM_MAX:
    svm_idx = X_tr.sample(SVM_MAX, random_state=SEED).index
    X_tr_svm, y_tr_svm = X_tr.loc[svm_idx], y_tr.loc[svm_idx]
else:
    X_tr_svm, y_tr_svm = X_tr, y_tr

# ----------------- Train, Evaluate, Compare -----------------
def eval_from_proba(ytrue, proba, thr=0.5):
    pred = (proba >= thr).astype(int)
    return dict(
        accuracy=accuracy_score(ytrue, pred),
        f1=f1_score(ytrue, pred),
        roc_auc=roc_auc_score(ytrue, proba),
        pr_auc=average_precision_score(ytrue, proba),
    )

results = {}

for name, pipe in models.items():
    print(f"\nTraining {name} ...")
    if name == "svm_rbf":
        pipe.fit(X_tr_svm, y_tr_svm)
    else:
        pipe.fit(X_tr, y_tr)

    proba = pipe.predict_proba(X_te)[:, 1]
    results[name] = eval_from_proba(y_te, proba)
    joblib.dump(pipe, os.path.join(ARTIFACT_DIR, f"{name}_pipeline.joblib"))

metrics = pd.DataFrame(results).T.sort_values("roc_auc", ascending=False)
print("\n=== Test metrics (no-CV) ===")
print(metrics)
metrics.to_csv(os.path.join(ARTIFACT_DIR, "metrics_simple.csv"))

# ----------------- Plots -----------------
plt.figure()
for name, pipe in models.items():
    RocCurveDisplay.from_estimator(pipe, X_te, y_te, name=name)
plt.title("ROC — Test"); plt.legend(); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "roc_simple.png"), dpi=150); plt.show()

plt.figure()
for name, pipe in models.items():
    PrecisionRecallDisplay.from_estimator(pipe, X_te, y_te, name=name)
plt.title("PR — Test"); plt.legend(); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "pr_simple.png"), dpi=150); plt.show()

ax = metrics[["roc_auc","pr_auc","accuracy","f1"]].plot(kind="bar")
ax.set_title("Model Comparison — Test (no-CV)")
ax.set_ylabel("Score")
ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "model_comparison_simple.png"), dpi=150); plt.show()

"""# Random Forest
## 3 different preprocessing
"""

# Not the final code. ignore it
# Preprocessing: read_csv(na_values='?') → drop your cols → fill race/medical_specialty='other'
# → Ordinal-encode ALL categoricals. Train RandomForest. Evaluate + visualize.

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay, classification_report, confusion_matrix
)

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"   # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

# Your exact drops
DROP_COLS = ['weight','max_glu_serum','A1Cresult','payer_code','encounter_id','patient_nbr']


# low_memory=False avoids DtypeWarning & speeds parsing on mixed-type cols
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
assert 'readmitted' in df.columns, "Target 'readmitted' not found."

# Drop exactly the columns from  notebook
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill 'race' and 'medical_specialty' with 'other' (as in your notebook)
for c in ['race', 'medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# Binary target: any readmission (<30 or >30) vs NO (same semantics as before)
y = (df['readmitted'].astype(str).str.upper() != 'NO').astype(int)
X = df.drop(columns=['readmitted']).copy()

# Numeric columns commonly present (without age_num)
num_cols = [c for c in [
    'time_in_hospital','num_lab_procedures','num_procedures','num_medications',
    'number_outpatient','number_emergency','number_inpatient','number_diagnoses'
] if c in X.columns]

# Everything else treated as categorical (ordinal-encoded)
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# - Numerics: median impute (no scaling; trees don’t need it)
# - Categoricals: impute most frequent, then OrdinalEncoder (LabelEncoder-like, multi-column)
ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    dtype=np.int64
)

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

cat_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("enc", ordinal_enc),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop"
)

# ---------------- Model: RandomForest ----------------
rf = RandomForestClassifier(
    n_estimators=500,
    max_depth=None,
    min_samples_leaf=1,
    random_state=SEED,
    n_jobs=-1,
    class_weight="balanced_subsample"  # handles imbalance a bit
)

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", rf),
])

# ---------------- Train ----------------
print("\nTraining RandomForest ...")
pipe.fit(X_train, y_train)

# ---------------- Evaluate ----------------
proba = pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (RandomForest) ===")
for k, v in metrics.items():
    print(f"{k:>8}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
# 1) ROC Curve
RocCurveDisplay.from_estimator(pipe, X_test, y_test, name="RandomForest")
plt.title("ROC — RandomForest (Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_roc.png"), dpi=160)
plt.show()

# 2) Precision–Recall Curve
PrecisionRecallDisplay.from_estimator(pipe, X_test, y_test, name="RandomForest")
plt.title("Precision–Recall — RandomForest (Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_pr.png"), dpi=160)
plt.show()

# 3) Top feature importances (from trained RF)
#    Recover transformed feature names: numeric first, then categorical encoded as ordinal (one column each)
def get_feature_names(prep: ColumnTransformer):
    names = []
    # numeric names as-is
    if num_cols:
        names.extend(num_cols)
    # categorical names: original column names (each is a single ordinal-encoded column)
    if cat_cols:
        names.extend(cat_cols)
    return names

feat_names = get_feature_names(pipe.named_steps["prep"])
importances = pipe.named_steps["clf"].feature_importances_
feat_imp = (pd.DataFrame({"feature": feat_names, "importance": importances})
            .sort_values("importance", ascending=False)
            .head(20))

print("\nTop 20 features by RF importance:")
print(feat_imp)

# Plot top-20 feature importances
plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance")
plt.title("RandomForest — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_feature_importance_top20.png"), dpi=160)
plt.show()

# ---------------- Save artifacts ----------------
joblib.dump(pipe, os.path.join(ARTIFACT_DIR, "rf_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "rf_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "rf_feature_importance_top20.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

# Not the final code.
# My preprocessing + tuned RandomForest for the UCI/Kaggle diabetes readmission dataset

import os, re, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt
from typing import Dict

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay, classification_report, confusion_matrix
)
from sklearn.experimental import enable_halving_search_cv  # noqa: F401
from sklearn.model_selection import HalvingGridSearchCV

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"  # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)
CACHE_DIR = "skcache"; os.makedirs(CACHE_DIR, exist_ok=True)

# Columns that are IDs/near-constant or not useful as-is
DROP_COLS = ["encounter_id", "patient_nbr", "weight", "payer_code", "examide", "citoglipton"]

# We KEEP max_glu_serum & A1Cresult and treat them as ordinal categories.

# ---------------- Helpers ----------------
def age_mid(a):
    """Convert age bracket like '[70-80)' -> 75.0"""
    if pd.isna(a): return np.nan
    m = re.match(r"\[(\d+)-(\d+)\)", str(a))
    return np.nan if not m else (int(m.group(1))+int(m.group(2)))/2

def bucket_icd9(code: str) -> str:
    """Broad ICD-9 buckets to reduce category explosion."""
    if pd.isna(code): return "icd_missing"
    s = str(code).strip()
    if s.startswith("V"): return "icd_V"
    if s.startswith("E"): return "icd_E"
    try: v = float(s)
    except ValueError: return "icd_other"
    if 390 <= v <= 459 or v == 785: return "circulatory"
    if 460 <= v <= 519 or v == 786: return "respiratory"
    if 520 <= v <= 579 or v == 787: return "digestive"
    if 250 <= v < 251:             return "diabetes_specific"
    if 800 <= v <= 999:            return "injury"
    if 710 <= v <= 739:            return "musculoskeletal"
    if 580 <= v <= 629 or v == 788:return "genitourinary"
    if 140 <= v <= 239:            return "neoplasms"
    return "other"

class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    """Group infrequent categories to 'RARE' (fit on train only). Place BEFORE imputation/one-hot."""
    def __init__(self, min_freq: int = 50):
        self.min_freq = min_freq
        self.frequent_maps_: Dict[str, set] = {}
        self.columns_: list = []

    def fit(self, X: pd.DataFrame, y=None):
        if not isinstance(X, pd.DataFrame):
            raise TypeError("RareCategoryGrouper expects a pandas DataFrame.")
        self.columns_ = X.columns.tolist()
        self.frequent_maps_ = {}
        for c in self.columns_:
            vc = X[c].astype(str).value_counts(dropna=False)
            self.frequent_maps_[c] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X, columns=self.columns_)
        Xo = X.copy()
        for c in self.columns_:
            keep = self.frequent_maps_[c]
            Xo[c] = Xo[c].astype(str).where(Xo[c].astype(str).isin(keep), "RARE")
        return Xo

# ---------------- Load ----------------
# low_memory=False prevents slow dtype guessing + DtypeWarning on mixed columns
df = pd.read_csv(DATA_PATH, na_values="?", low_memory=False)
assert "readmitted" in df.columns, "Target 'readmitted' not found."

# Basic clean
df.drop_duplicates(inplace=True)
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill some key cats
for c in ["race", "medical_specialty"]:
    if c in df.columns:
        df[c] = df[c].fillna("other")

# Map glu/A1C to ordered categories (if present) to keep signal
glu_map = {"None": 0, "Norm": 1, ">200": 2, ">300": 3}
a1c_map = {"None": 0, "Norm": 1, ">7": 2, ">8": 3}
if "max_glu_serum" in df.columns:
    df["max_glu_serum"] = df["max_glu_serum"].map(glu_map).astype("float64")
if "A1Cresult" in df.columns:
    df["A1Cresult"] = df["A1Cresult"].map(a1c_map).astype("float64")

# Target (binary: any readmission vs NO)
y = (df["readmitted"].astype(str).str.upper() != "NO").astype(int)
X = df.drop(columns=["readmitted"]).copy()

# Feature engineering
if "age" in X.columns:
    X["age_num"] = X["age"].apply(age_mid).astype("float64")
for d in ["diag_1", "diag_2", "diag_3"]:
    if d in X.columns:
        X[f"{d}_bucket"] = X[d].apply(bucket_icd9)

# Derived numerics (light, helpful)
if set(["number_outpatient","number_emergency","number_inpatient"]).issubset(X.columns):
    X["util_visits"] = (X["number_outpatient"].fillna(0) +
                        X["number_emergency"].fillna(0) +
                        X["number_inpatient"].fillna(0)).astype("float64")
if set(["num_medications","time_in_hospital"]).issubset(X.columns):
    X["meds_per_day"] = (X["num_medications"].astype("float64") /
                         (X["time_in_hospital"].astype("float64") + 1.0))

# ---------------- Column sets ----------------
likely_numeric = [
    "time_in_hospital","num_lab_procedures","num_procedures","num_medications",
    "number_outpatient","number_emergency","number_inpatient","number_diagnoses",
    "age_num","A1Cresult","max_glu_serum","util_visits","meds_per_day"
]
num_cols = [c for c in likely_numeric if c in X.columns]

# Treat everything else as categorical for one-hot (after rare-group)
cat_cols = [c for c in X.columns if c not in num_cols]

# Remove single-valued columns (post engineering)
drop_single = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]
if drop_single:
    X.drop(columns=drop_single, inplace=True)
    num_cols = [c for c in num_cols if c not in drop_single]
    cat_cols = [c for c in cat_cols if c not in drop_single]

print("Numeric:", num_cols)
print("Categorical:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)
pos_weight = (y_train.shape[0] - y_train.sum()) / max(1, y_train.sum())

# IMPORTANT: rare grouper BEFORE impute/one-hot so it can see DataFrame + levels
cat_pipe = Pipeline(steps=[
    ("rare", RareCategoryGrouper(min_freq=50)),
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
])

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop",
    verbose_feature_names_out=False,
)

# ---------------- Model ----------------
rf = RandomForestClassifier(
    n_estimators=500,
    random_state=SEED,
    n_jobs=-1,
    class_weight="balanced_subsample"
)

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", rf)
])

# ---------------- Light tuning with HalvingGridSearchCV ----------------
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)
param_grid = {
    "clf__n_estimators": [500, 800],
    "clf__max_depth": [None, 12, 18],
    "clf__min_samples_leaf": [1, 3, 5],
    "clf__max_features": ["sqrt", 0.4],
}

search = HalvingGridSearchCV(
    estimator=pipe,
    param_grid=param_grid,
    factor=3,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    verbose=1,
    refit=True
)

print("\nSearching RandomForest …")
search.fit(X_train, y_train)
print("Best params:", search.best_params_, "| Best CV AUC:", round(search.best_score_, 4))
best_pipe = search.best_estimator_

# ---------------- Evaluate ----------------
proba = best_pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (RandomForest, tuned) ===")
for k, v in metrics.items():
    print(f"{k:>8}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
# 1) ROC
RocCurveDisplay.from_estimator(best_pipe, X_test, y_test, name="RandomForest (tuned)")
plt.title("ROC — RandomForest (Tuned)"); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_mine_roc.png"), dpi=160)
plt.show()

# 2) PR
PrecisionRecallDisplay.from_estimator(best_pipe, X_test, y_test, name="RandomForest (tuned)")
plt.title("Precision–Recall — RandomForest (Tuned)"); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_mine_pr.png"), dpi=160)
plt.show()

# 3) Top-20 feature importances
#    Get feature names after preprocessing (num first, then one-hot categories)
def get_feature_names(prep: ColumnTransformer):
    names = []
    # numeric names
    names.extend(prep.transformers_[0][2])  # num_cols
    # categorical one-hot names
    ohe = prep.named_transformers_["cat"].named_steps["ohe"]
    cat_input = prep.transformers_[1][2]
    ohe_names = ohe.get_feature_names_out(cat_input).tolist()
    names.extend(ohe_names)
    return names

feat_names = get_feature_names(best_pipe.named_steps["prep"])
importances = best_pipe.named_steps["clf"].feature_importances_
feat_imp = (pd.DataFrame({"feature": feat_names, "importance": importances})
            .sort_values("importance", ascending=False)
            .head(20))

print("\nTop 20 features by RF importance:")
print(feat_imp)

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance"); plt.title("RandomForest (Tuned) — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_mine_feature_importance_top20.png"), dpi=160)
plt.show()

# ---------------- Save artifacts ----------------
joblib.dump(best_pipe, os.path.join(ARTIFACT_DIR, "rf_mine_best_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "rf_mine_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "rf_mine_feature_importance_top20.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

# Not the final code. ignore it
# My preprocessing (age midpoint, ICD buckets, rare-category grouping, one-hot)

import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt, joblib
from typing import Dict
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay, classification_report, confusion_matrix
)

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

# Drop IDs/near-constant
DROP_COLS = ["encounter_id", "patient_nbr", "weight", "payer_code", "examide", "citoglipton"]

# ---------------- Helpers ----------------
def age_mid(a):
    if pd.isna(a): return np.nan
    m = re.match(r"\[(\d+)-(\d+)\)", str(a))
    return np.nan if not m else (int(m.group(1))+int(m.group(2)))/2

def bucket_icd9(code: str) -> str:
    if pd.isna(code): return "icd_missing"
    s = str(code).strip()
    if s.startswith("V"): return "icd_V"
    if s.startswith("E"): return "icd_E"
    try: v = float(s)
    except ValueError: return "icd_other"
    if 390 <= v <= 459 or v == 785: return "circulatory"
    if 460 <= v <= 519 or v == 786: return "respiratory"
    if 520 <= v <= 579 or v == 787: return "digestive"
    if 250 <= v < 251:             return "diabetes_specific"
    if 800 <= v <= 999:            return "injury"
    if 710 <= v <= 739:            return "musculoskeletal"
    if 580 <= v <= 629 or v == 788:return "genitourinary"
    if 140 <= v <= 239:            return "neoplasms"
    return "other"

class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    def __init__(self, min_freq: int = 50):
        self.min_freq = min_freq
        self.frequent_maps_: Dict[str, set] = {}
        self.columns_: list = []

    def fit(self, X: pd.DataFrame, y=None):
        if not isinstance(X, pd.DataFrame):
            raise TypeError("RareCategoryGrouper expects a pandas DataFrame.")
        self.columns_ = X.columns.tolist()
        self.frequent_maps_ = {}
        for c in self.columns_:
            vc = X[c].astype(str).value_counts(dropna=False)
            self.frequent_maps_[c] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X, columns=self.columns_)
        Xo = X.copy()
        for c in self.columns_:
            keep = self.frequent_maps_[c]
            Xo[c] = Xo[c].astype(str).where(Xo[c].astype(str).isin(keep), "RARE")
        return Xo

# ---------------- Load ----------------
df = pd.read_csv(DATA_PATH, na_values="?", low_memory=False)
assert "readmitted" in df.columns, "Target 'readmitted' not found."
df.drop_duplicates(inplace=True)
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill a few key categoricals
for c in ["race", "medical_specialty"]:
    if c in df.columns:
        df[c] = df[c].fillna("other")

# Map ordered labs (keep signal)
glu_map = {"None": 0, "Norm": 1, ">200": 2, ">300": 3}
a1c_map = {"None": 0, "Norm": 1, ">7": 2, ">8": 3}
if "max_glu_serum" in df.columns:
    df["max_glu_serum"] = df["max_glu_serum"].map(glu_map).astype("float64")
if "A1Cresult" in df.columns:
    df["A1Cresult"] = df["A1Cresult"].map(a1c_map).astype("float64")

# Target and features
y = (df["readmitted"].astype(str).str.upper() != "NO").astype(int)
X = df.drop(columns=["readmitted"]).copy()

# Feature engineering
if "age" in X.columns:
    X["age_num"] = X["age"].apply(age_mid).astype("float64")
for d in ["diag_1", "diag_2", "diag_3"]:
    if d in X.columns:
        X[f"{d}_bucket"] = X[d].apply(bucket_icd9)

# Derived numerics
if set(["number_outpatient","number_emergency","number_inpatient"]).issubset(X.columns):
    X["util_visits"] = (X["number_outpatient"].fillna(0) +
                        X["number_emergency"].fillna(0) +
                        X["number_inpatient"].fillna(0)).astype("float64")
if set(["num_medications","time_in_hospital"]).issubset(X.columns):
    X["meds_per_day"] = (X["num_medications"].astype("float64") /
                         (X["time_in_hospital"].astype("float64") + 1.0))

# Column sets
likely_numeric = [
    "time_in_hospital","num_lab_procedures","num_procedures","num_medications",
    "number_outpatient","number_emergency","number_inpatient","number_diagnoses",
    "age_num","A1Cresult","max_glu_serum","util_visits","meds_per_day"
]
num_cols = [c for c in likely_numeric if c in X.columns]
cat_cols = [c for c in X.columns if c not in num_cols]

# Drop single-valued columns
drop_single = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]
if drop_single:
    X.drop(columns=drop_single, inplace=True)
    num_cols = [c for c in num_cols if c not in drop_single]
    cat_cols = [c for c in cat_cols if c not in drop_single]

print("Numeric:", num_cols)
print("Categorical:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# ---------------- Preprocessing ----------------
cat_pipe = Pipeline(steps=[
    ("rare", RareCategoryGrouper(min_freq=50)),
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
])

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop",
    verbose_feature_names_out=False,
)

# ---------------- RandomForest (single fit, no CV) ----------------
rf = RandomForestClassifier(
    n_estimators=500,
    max_depth=None,
    min_samples_leaf=2,
    max_features="sqrt",
    random_state=SEED,
    n_jobs=-1,
    class_weight="balanced_subsample"
)

pipe = Pipeline(steps=[("prep", preproc), ("clf", rf)])

print("\nTraining RandomForest (single fit, no CV) ...")
pipe.fit(X_train, y_train)

# ---------------- Evaluate ----------------
proba = pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (RandomForest) ===")
for k, v in metrics.items():
    print(f"{k:>8}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
RocCurveDisplay.from_estimator(pipe, X_test, y_test, name="RF (single fit)")
plt.title("ROC — RandomForest (Test)"); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_fast_roc.png"), dpi=160); plt.show()

PrecisionRecallDisplay.from_estimator(pipe, X_test, y_test, name="RF (single fit)")
plt.title("Precision–Recall — RandomForest (Test)"); plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_fast_pr.png"), dpi=160); plt.show()

# Top-20 feature importances
def get_feature_names(prep: ColumnTransformer):
    names = []
    names.extend(prep.transformers_[0][2])  # numeric inputs
    ohe = prep.named_transformers_["cat"].named_steps["ohe"]
    cat_input = prep.transformers_[1][2]
    names.extend(ohe.get_feature_names_out(cat_input).tolist())
    return names

feat_names = get_feature_names(pipe.named_steps["prep"])
importances = pipe.named_steps["clf"].feature_importances_
feat_imp = (pd.DataFrame({"feature": feat_names, "importance": importances})
            .sort_values("importance", ascending=False).head(20))

print("\nTop 20 features by RF importance:")
print(feat_imp)

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance"); plt.title("RandomForest — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_fast_feature_importance_top20.png"), dpi=160)
plt.show()

# ---------------- Save ----------------
joblib.dump(pipe, os.path.join(ARTIFACT_DIR, "rf_fast_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "rf_fast_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "rf_fast_feature_importance_top20.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay, classification_report, confusion_matrix
)
from scipy.stats import randint, uniform

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

DROP_COLS = ['weight','max_glu_serum','A1Cresult','payer_code','encounter_id','patient_nbr']

# ---------------- Load + preprocessing ----------------
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
assert 'readmitted' in df.columns, "Target 'readmitted' not found."

# Drop fixed columns
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill 'race' and 'medical_specialty' with 'other'
for c in ['race', 'medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# Binary target
y = (df['readmitted'].astype(str).str.upper() != 'NO').astype(int)
X = df.drop(columns=['readmitted']).copy()

# EXTRA: turn age bracket into numeric midpoint feature
if 'age' in X.columns:
    age_map = {
        '[0-10)': 5,
        '[10-20)': 15,
        '[20-30)': 25,
        '[30-40)': 35,
        '[40-50)': 45,
        '[50-60)': 55,
        '[60-70)': 65,
        '[70-80)': 75,
        '[80-90)': 85,
        '[90-100)': 95
    }
    X['age_num'] = X['age'].map(age_map).astype(float)

# Numeric columns (original + new age_num if present)
num_cols = [c for c in [
    'time_in_hospital','num_lab_procedures','num_procedures','num_medications',
    'number_outpatient','number_emergency','number_inpatient','number_diagnoses',
    'age_num'
] if c in X.columns]

# Everything else categorical (ordinal-encoded)
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# ---------------- Preprocessing ----------------
ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    dtype=np.int64
)

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

cat_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("enc", ordinal_enc),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop"
)

# ---------------- Base RandomForest ----------------
rf = RandomForestClassifier(
    random_state=SEED,
    n_jobs=-1
)

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", rf),
])

# ---------------- Hyperparameter search (RandomForest only) ----------------
param_distributions = {
    "clf__n_estimators": randint(200, 800),
    "clf__max_depth": [None, 10, 20, 40],
    "clf__min_samples_split": randint(2, 20),
    "clf__min_samples_leaf": randint(1, 15),
    "clf__max_features": ["sqrt", "log2", 0.3, 0.5, 0.7],
    "clf__class_weight": [None, "balanced", "balanced_subsample"],
}

search = RandomizedSearchCV(
    estimator=pipe,
    param_distributions=param_distributions,
    n_iter=30,                # increase for more thorough search (slower)
    scoring="accuracy",       # optimizes for accuracy
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=SEED
)

print("\nTuning RandomForest with RandomizedSearchCV ...")
search.fit(X_train, y_train)

print("\nBest CV accuracy: ", search.best_score_)
print("Best params:")
for k, v in search.best_params_.items():
    print(f"  {k}: {v}")

# Use best model
best_pipe = search.best_estimator_

# ---------------- Evaluate ----------------
print("\nEvaluating best RandomForest on test set...")
proba = best_pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (RandomForest, tuned) ===")
for k, v in metrics.items():
    print(f"{k:>8}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
RocCurveDisplay.from_estimator(best_pipe, X_test, y_test, name="RandomForest (tuned)")
plt.title("ROC — RandomForest (tuned, Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_tuned_roc.png"), dpi=160)
plt.show()

PrecisionRecallDisplay.from_estimator(best_pipe, X_test, y_test, name="RandomForest (tuned)")
plt.title("Precision–Recall — RandomForest (tuned, Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_tuned_pr.png"), dpi=160)
plt.show()

# ---------------- Feature importances ----------------
def get_feature_names(num_cols, cat_cols):
    names = []
    if num_cols:
        names.extend(num_cols)
    if cat_cols:
        names.extend(cat_cols)
    return names

feat_names = get_feature_names(num_cols, cat_cols)
importances = best_pipe.named_steps["clf"].feature_importances_
feat_imp = (pd.DataFrame({"feature": feat_names, "importance": importances})
            .sort_values("importance", ascending=False)
            .head(20))

print("\nTop 20 features by RF importance:")
print(feat_imp)

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance")
plt.title("RandomForest (tuned) — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_tuned_feature_importance_top20.png"), dpi=160)
plt.show()

# ---------------- Save artifacts ----------------
joblib.dump(best_pipe, os.path.join(ARTIFACT_DIR, "rf_tuned_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "rf_tuned_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "rf_tuned_feature_importance_top20.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

#not the final code . Ignore it
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    classification_report, confusion_matrix
)
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import label_binarize
from scipy.stats import randint

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"   # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

DROP_COLS = ['weight','max_glu_serum','A1Cresult','payer_code','encounter_id','patient_nbr']


# ---------------- Custom transformer: group rare categories ----------------
class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    """
    For each categorical column, replace categories that appear
    less than min_freq times with '__RARE__'.
    """
    def __init__(self, min_freq=200):
        self.min_freq = min_freq
        self.frequent_categories_ = None

    def fit(self, X, y=None):
        X_df = pd.DataFrame(X).astype(str)
        self.frequent_categories_ = {}
        for col in X_df.columns:
            vc = X_df[col].value_counts()
            self.frequent_categories_[col] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        X_df = pd.DataFrame(X).astype(str)
        for col in X_df.columns:
            freq = self.frequent_categories_.get(col, set())
            X_df[col] = np.where(X_df[col].isin(freq), X_df[col], "__RARE__")
        return X_df.values  # ndarray for compatibility


# ---------------- Load + preprocessing ----------------
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
assert 'readmitted' in df.columns, "Target 'readmitted' not found."

# Drop fixed columns
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill 'race' and 'medical_specialty' with 'other'
for c in ['race', 'medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# Simplify diagnosis codes: use first 3 characters (reduces cardinality)
for diag_col in ['diag_1', 'diag_2', 'diag_3']:
    if diag_col in df.columns:
        df[diag_col] = df[diag_col].astype(str).str.strip()
        df[diag_col] = df[diag_col].replace('nan', np.nan)
        df[diag_col] = df[diag_col].str[:3]

# --------- 3-class target (NO, <30, >30) ---------
# keep original 3 categories, just standardize to upper case
df['readmitted'] = df['readmitted'].astype(str).str.upper()
y = df['readmitted']                 # NO / <30 / >30 as 3 classes
X = df.drop(columns=['readmitted']).copy()

# Age numeric feature (midpoint of bracket)
if 'age' in X.columns:
    age_map = {
        '[0-10)': 5,
        '[10-20)': 15,
        '[20-30)': 25,
        '[30-40)': 35,
        '[40-50)': 45,
        '[50-60)': 55,
        '[60-70)': 65,
        '[70-80)': 75,
        '[80-90)': 85,
        '[90-100)': 95
    }
    X['age_num'] = X['age'].map(age_map).astype(float)

# Numeric columns (original + new age_num if present)
num_cols = [c for c in [
    'time_in_hospital','num_lab_procedures','num_procedures','num_medications',
    'number_outpatient','number_emergency','number_inpatient','number_diagnoses',
    'age_num'
] if c in X.columns]

# Everything else categorical (ordinal-encoded after rare-grouping)
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# ---------------- Preprocessing ----------------
ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    dtype=np.int64
)

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

cat_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("rare", RareCategoryGrouper(min_freq=200)),
    ("enc", ordinal_enc),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop"
)

# ---------------- RandomForest (base) ----------------
rf = RandomForestClassifier(
    random_state=SEED,
    n_jobs=-1
)

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", rf),
])

# ---------------- Hyperparameter search (RandomForest only) ----------------
param_distributions = {
    "clf__n_estimators": randint(300, 900),
    "clf__max_depth": [None, 10, 20, 40],
    "clf__min_samples_split": randint(2, 20),
    "clf__min_samples_leaf": randint(1, 15),
    "clf__max_features": ["sqrt", "log2", 0.3, 0.5, 0.7],
    "clf__class_weight": [None, "balanced", "balanced_subsample"],
}

search = RandomizedSearchCV(
    estimator=pipe,
    param_distributions=param_distributions,
    n_iter=30,
    scoring="accuracy",
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=SEED
)

print("\nTuning RandomForest (3-class) with RandomizedSearchCV...")
search.fit(X_train, y_train)

print("\nBest CV accuracy: ", search.best_score_)
print("Best params:")
for k, v in search.best_params_.items():
    print(f"  {k}: {v}")

best_pipe = search.best_estimator_

# ---------------- Evaluate ----------------
print("\nEvaluating best 3-class RandomForest on test set...")
proba = best_pipe.predict_proba(X_test)         # shape (n_samples, n_classes)
pred  = best_pipe.predict(X_test)
classes = best_pipe.classes_                    # e.g. ['<30','>30','NO']

# Multi-class metrics
acc = accuracy_score(y_test, pred)
f1_macro = f1_score(y_test, pred, average="macro")
f1_weighted = f1_score(y_test, pred, average="weighted")

# ROC AUC (macro, one-vs-rest)
roc_auc_macro = roc_auc_score(y_test, proba, multi_class="ovr", average="macro")

# PR AUC (macro) – need binarized y
y_test_bin = label_binarize(y_test, classes=classes)
pr_auc_macro = average_precision_score(y_test_bin, proba, average="macro")

metrics = {
    "accuracy": acc,
    "f1_macro": f1_macro,
    "f1_weighted": f1_weighted,
    "roc_auc_macro": roc_auc_macro,
    "pr_auc_macro": pr_auc_macro,
}
print("\n=== Test metrics (RandomForest, 3-class) ===")
for k, v in metrics.items():
    print(f"{k:>14}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred, labels=classes))

print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Feature importances ----------------
def get_feature_names(num_cols, cat_cols):
    names = []
    if num_cols:
        names.extend(num_cols)
    if cat_cols:
        names.extend(cat_cols)
    return names

feat_names = get_feature_names(num_cols, cat_cols)
importances = best_pipe.named_steps["clf"].feature_importances_
feat_imp = (pd.DataFrame({"feature": feat_names, "importance": importances})
            .sort_values("importance", ascending=False)
            .head(20))

print("\nTop 20 features by RF importance:")
print(feat_imp)

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance")
plt.title("RandomForest (3-class, tuned + rare) — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_3class_feature_importance_top20.png"), dpi=160)
plt.show()

# ---------------- Save artifacts ----------------
joblib.dump(best_pipe, os.path.join(ARTIFACT_DIR, "rf_3class_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "rf_3class_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "rf_3class_feature_importance_top20.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

#not the final code. ignore it


import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, label_binarize
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    roc_auc_score,
    average_precision_score,
    balanced_accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
    RocCurveDisplay,
    PrecisionRecallDisplay,
)
from scipy.stats import randint

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)

DATA_PATH = "diabetic_data.csv"   # change if needed
ARTIFACT_DIR = "artifacts"
os.makedirs(ARTIFACT_DIR, exist_ok=True)

DROP_COLS = ['weight', 'max_glu_serum', 'A1Cresult',
             'payer_code', 'encounter_id', 'patient_nbr']


# ---------------- Load + preprocessing (simple) ----------------
t0_total = time.time()
print("Loading data ...")
t0 = time.time()
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
print(f"Loaded data in {time.time() - t0:.2f} seconds")
assert 'readmitted' in df.columns, "Target 'readmitted' not found."
print("Initial shape:", df.shape)

# Drop fixed columns (your original drops)
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

# Fill 'race' and 'medical_specialty' with 'other' (your notebook logic)
for c in ['race', 'medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# 3-class target (NO, <30, >30)
df['readmitted'] = df['readmitted'].astype(str).str.upper()
y = df['readmitted']                 # raw 3-class labels
X = df.drop(columns=['readmitted']).copy()

# Numeric age feature (midpoint of bracket), and drop raw 'age' column
if 'age' in X.columns:
    age_map = {
        '[0-10)': 5,
        '[10-20)': 15,
        '[20-30)': 25,
        '[30-40)': 35,
        '[40-50)': 45,
        '[50-60)': 55,
        '[60-70)': 65,
        '[70-80)': 75,
        '[80-90)': 85,
        '[90-100)': 95
    }
    X['age_num'] = X['age'].map(age_map).astype(float)
    # Drop the categorical age to avoid redundant info
    X.drop(columns=['age'], inplace=True)

# Numeric columns (your list + age_num)
num_cols = [c for c in [
    'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',
    'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses',
    'age_num'
] if c in X.columns]

# Everything else treated as categorical (no rare grouping, no diag truncation)
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ---------------- Train/test split ----------------
print("\nSplitting train/test ...")
t0 = time.time()
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=SEED,
    stratify=y
)
print(f"Data split in {time.time() - t0:.2f} seconds")
print("Train shape:", X_train.shape, "Test shape:", X_test.shape)

# ---------------- Preprocessing pipeline ----------------
ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    dtype=np.int64,
)

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
])

cat_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("enc", ordinal_enc),
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop"
)

print("\nPreprocessing defined.")

# ---------------- RandomForest model + search space ----------------
rf = RandomForestClassifier(
    random_state=SEED,
    n_jobs=-1,
)

param_distributions = {
    "clf__n_estimators": randint(300, 900),
    "clf__max_depth": [None, 10, 20, 40],
    "clf__min_samples_split": randint(2, 20),
    "clf__min_samples_leaf": randint(1, 15),
    "clf__max_features": ["sqrt", "log2", 0.3, 0.5, 0.7],
    # Only allow balancing, no "None" to force caring about minority classes
    "clf__class_weight": ["balanced", "balanced_subsample"],
}

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", rf),
])

# ---------------- Hyperparameter search (sharpened) ----------------
print("\nTuning RandomForest (3-class) with RandomizedSearchCV "
      "using balanced_accuracy ...")
search = RandomizedSearchCV(
    estimator=pipe,
    param_distributions=param_distributions,
    n_iter=30,
    scoring="balanced_accuracy",      # key change: care about all classes
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=SEED,
)

t0 = time.time()
search.fit(X_train, y_train)
train_time = time.time() - t0

print(f"\nRandomForest - best CV balanced_accuracy: {search.best_score_:.4f}")
print("Best params:")
for k, v in search.best_params_.items():
    print(f"  {k}: {v}")

best_pipe = search.best_estimator_

# ---------------- Evaluate on test set ----------------
print("\nEvaluating best 3-class RandomForest on test set...")
t0 = time.time()
proba = best_pipe.predict_proba(X_test)
pred = best_pipe.predict(X_test)
infer_time = time.time() - t0

classes = best_pipe.classes_   # typically ['<30', '>30', 'NO']

acc = accuracy_score(y_test, pred)
f1_macro = f1_score(y_test, pred, average="macro")
f1_weighted = f1_score(y_test, pred, average="weighted")
bal_acc = balanced_accuracy_score(y_test, pred)

roc_auc_macro = roc_auc_score(y_test, proba, multi_class="ovr", average="macro")
y_test_bin = label_binarize(y_test, classes=classes)
pr_auc_macro = average_precision_score(y_test_bin, proba, average="macro")

metrics = {
    "accuracy": acc,
    "f1_macro": f1_macro,
    "f1_weighted": f1_weighted,
    "balanced_accuracy": bal_acc,
    "roc_auc_macro": roc_auc_macro,
    "pr_auc_macro": pr_auc_macro,
}

print("\n=== Test metrics (RandomForest, 3-class, sharpened) ===")
for k, v in metrics.items():
    print(f"{k:>18}: {v:.4f}")

print("\nTraining time (RF search): "
      f"{train_time:.2f} seconds")
print("Inference time on test set: "
      f"{infer_time:.4f} seconds")

print("\nConfusion Matrix (rows=true, cols=pred):")
cm = confusion_matrix(y_test, pred, labels=classes)
print(cm)

print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
# 1) Confusion matrix plot
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
plt.figure()
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix — RandomForest (3-class, sharpened)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_3class_sharpened_confusion_matrix.png"),
            dpi=160)
plt.close()

# 2) ROC curves (one-vs-rest for each class)
plt.figure()
ax = plt.gca()
for i, cls in enumerate(classes):
    RocCurveDisplay.from_predictions(
        y_test_bin[:, i],
        proba[:, i],
        name=f"Class {cls}",
        ax=ax,
    )
plt.title("ROC Curves — RandomForest (3-class, sharpened)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_3class_sharpened_roc_ovr.png"),
            dpi=160)
plt.close()

# 3) Precision–Recall curves (one-vs-rest)
plt.figure()
ax = plt.gca()
for i, cls in enumerate(classes):
    PrecisionRecallDisplay.from_predictions(
        y_test_bin[:, i],
        proba[:, i],
        name=f"Class {cls}",
        ax=ax,
    )
plt.title("Precision–Recall Curves — RandomForest (3-class, sharpened)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "rf_3class_sharpened_pr_ovr.png"),
            dpi=160)
plt.close()

# 4) Feature importances (top 20)
def get_feature_names(num_cols, cat_cols):
    names = []
    if num_cols:
        names.extend(num_cols)
    if cat_cols:
        names.extend(cat_cols)
    return names

feat_names = get_feature_names(num_cols, cat_cols)
importances = best_pipe.named_steps["clf"].feature_importances_

feat_imp = (
    pd.DataFrame({"feature": feat_names, "importance": importances})
    .sort_values("importance", ascending=False)
    .head(20)
)

print("\nTop 20 features by RF importance (sharpened):")
print(feat_imp)

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["importance"][::-1])
plt.xlabel("Importance")
plt.title("RandomForest (3-class, sharpened) — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR,
                         "rf_3class_sharpened_feature_importance_top20.png"),
            dpi=160)
plt.close()

# ---------------- Save artifacts ----------------
joblib.dump(best_pipe,
            os.path.join(ARTIFACT_DIR, "rf_3class_sharpened_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(
    os.path.join(ARTIFACT_DIR, "rf_3class_sharpened_metrics.csv"),
    index=False,
)
feat_imp.to_csv(
    os.path.join(ARTIFACT_DIR,
                 "rf_3class_sharpened_feature_importance_top20.csv"),
    index=False,
)

print(f"\nTotal script time: {time.time() - t0_total:.2f} seconds")
print(f"Artifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

#not the final code. ignore it

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve, auc)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE

sns.set(style="whitegrid", font_scale=1.2)
plt.rcParams['figure.figsize'] = (12, 8)

# Step 1: Load & Initial Clean
df = pd.read_csv('diabetic_data.csv', na_values='?')
print(f"Dataset shape: {df.shape}")
df = df[df['gender'] != 'Unknown/Invalid']  # Drop invalid genders
df['readmitted'] = (df['readmitted'] == '<30').astype(int)  # Binary target: 1 = <30 days
print(f"Readmission rate: {df['readmitted'].mean():.3f} ({df['readmitted'].sum()} / {len(df)})")

# Drop high-missing columns
df.drop(['weight', 'payer_code', 'medical_specialty'], axis=1, errors='ignore', inplace=True)
df.drop(['encounter_id', 'patient_nbr'], axis=1, inplace=True)  # Drop IDs

# Step 2: Feature Engineering (Fixed - No More TypeErrors!)
# Race
df['race'] = df['race'].fillna('Caucasian').replace({'Asian': 'Other', 'Hispanic': 'Other'})

# Age to midpoint
age_map = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45,
           '[50-60)': 55, '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}
df['age'] = df['age'].map(age_map)

# Admission Type (simplified mapping)
adm_map = {1: 'Emergency', 2: 'Emergency', 3: 'Elective', 4: 'Newborn', 7: 'Trauma Center'}
df['admission_type_id'] = df['admission_type_id'].map(adm_map).fillna('Emergency')

# Discharge (Home vs Other)
home_codes = [1, 6, 8, 13, 19]
df['discharge_disposition_id'] = df['discharge_disposition_id'].apply(
    lambda x: 'Home' if pd.notna(x) and x in home_codes else 'Other'
)

# Admission Source
src_map = {1: 'Referral', 2: 'Referral', 3: 'Referral', 7: 'Emergency'}
df['admission_source_id'] = df['admission_source_id'].map(src_map).fillna('Other')

def map_diag(series):
    # Convert to numeric FIRST (handles strings/NaN safely)
    numeric_series = pd.to_numeric(series, errors='coerce')
    # Now apply conditions (all numeric, no TypeError)
    def categorize(val):
        if pd.isna(val):
            return 'Other'
        if 390 <= val <= 459:
            return 'Circulatory'
        elif 460 <= val <= 519:
            return 'Respiratory'
        elif 520 <= val <= 579:
            return 'Digestive'
        elif 250 <= val < 251:
            return 'Diabetes'
        elif 800 <= val <= 999:
            return 'Injury'
        elif 710 <= val <= 739:
            return 'Musculoskeletal'
        elif 580 <= val <= 629:
            return 'Genitourinary'
        elif 140 <= val <= 239:
            return 'Neoplasms'
        else:
            return 'Other'
    return numeric_series.apply(categorize)

for c in ['diag_1', 'diag_2', 'diag_3']:
    df[c] = map_diag(df[c])

# Glucose & A1C
df['max_glu_serum'] = df['max_glu_serum'].map({'>200': 2, '>300': 2, 'Norm': 1, 'None': 0}).fillna(0)
df['A1Cresult'] = df['A1Cresult'].map({'>8': 2, '>7': 2, 'Norm': 1, 'None': 0}).fillna(0)

# Change
df['change'] = df['change'].map({'Ch': 'Yes', 'No': 'No'}).fillna('No')

# Fill remaining categoricals with mode
obj_cols = df.select_dtypes('object').columns.drop('readmitted', errors='ignore')
for col in obj_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

# Step 3: Encoding
le = LabelEncoder()
for col in obj_cols:
    df[col] = le.fit_transform(df[col].astype(str))

# Step 4: Split, SMOTE, Scale
X = df.drop('readmitted', axis=1)
y = df['readmitted']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
print(f"After SMOTE: Train shape {X_train_res.shape}, class balance: {np.bincount(y_train_res)}")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)

# Step 5: Models with Hyperparams
models = {
    'Logistic Regression': LogisticRegression(C=0.5, max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=300, max_depth=12, min_samples_leaf=5, random_state=42, n_jobs=-1),
    'SVM (RBF)': SVC(C=1.0, gamma='scale', probability=True, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='logloss'),
    'LightGBM': LGBMClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, num_leaves=50, random_state=42, verbosity=-1)
}

results = {}
predictions = {}
probs = {}

print("\nTraining Models...")
for name, model in models.items():
    print(f"  - {name}")
    # Fit (subsample SVM for speed)
    if 'SVM' in name:
        model.fit(X_train_scaled[:15000], y_train_res[:15000])
    else:
        model.fit(X_train_scaled, y_train_res)

    # Predict
    pred = model.predict(X_test_scaled)
    if hasattr(model, 'predict_proba'):
        prob = model.predict_proba(X_test_scaled)[:, 1]
    else:
        prob = model.decision_function(X_test_scaled)
        prob = (prob - prob.min()) / (prob.max() - prob.min() + 1e-8)  # Normalize

    predictions[name] = pred
    probs[name] = prob

    results[name] = {
        'Accuracy': accuracy_score(y_test, pred),
        'Precision': precision_score(y_test, pred, zero_division=0),
        'Recall': recall_score(y_test, pred),
        'F1': f1_score(y_test, pred),
        'AUC': roc_auc_score(y_test, prob)
    }

# Step 6: Results Table
results_df = pd.DataFrame(results).T.sort_values('AUC', ascending=False)
print("\n" + "="*60)
print("MODEL PERFORMANCE COMPARISON")
print("="*60)
print(results_df.round(4))

# Step 7: Visualizations
fig = plt.figure(figsize=(20, 15))

# 1. Metrics Bar Plot
ax1 = plt.subplot(2, 3, 1)
results_df[['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].plot(kind='bar', ax=ax1, width=0.8)
plt.title('Model Metrics Comparison')
plt.xticks(rotation=45, ha='right')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.ylim(0, 1)

# 2. ROC Curves
ax2 = plt.subplot(2, 3, 2)
for name, prob in probs.items():
    fpr, tpr, _ = roc_curve(y_test, prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC={results[name]['AUC']:.3f})", linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', alpha=0.7)
plt.xlim([0, 1]); plt.ylim([0, 1])
plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend(fontsize=9)

# 3. Precision-Recall Curves
ax3 = plt.subplot(2, 3, 3)
for name, prob in probs.items():
    precision, recall, _ = precision_recall_curve(y_test, prob)
    plt.plot(recall, precision, label=f"{name}", linewidth=2)
plt.xlabel('Recall'); plt.ylabel('Precision')
plt.title('Precision-Recall Curves')
plt.legend(fontsize=9)

# 4. Confusion Matrix for Winner
winner = results_df.index[0]
cm = confusion_matrix(y_test, predictions[winner])
ax4 = plt.subplot(2, 3, 4)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4, cbar=False)
ax4.set_title(f'Confusion Matrix - Winner: {winner}')
ax4.set_xlabel('Predicted'); ax4.set_ylabel('Actual')

# 5. Feature Importance (Random Forest)
ax5 = plt.subplot(2, 3, 5)
if 'Random Forest' in models:
    importances = models['Random Forest'].feature_importances_
    top_idx = np.argsort(importances)[-10:]
    sns.barplot(x=importances[top_idx], y=X.columns[top_idx], ax=ax5)
ax5.set_title('Top 10 Features - Random Forest')
ax5.set_xlabel('Importance')

# 6. AUC Bar (Highlighted Winner)
ax6 = plt.subplot(2, 3, 6)
colors = ['gold' if idx == 0 else 'lightblue' for idx in range(len(results_df))]
results_df['AUC'].plot(kind='bar', ax=ax6, color=colors)
plt.title('AUC Scores (Gold = Winner)')
plt.ylabel('AUC'); plt.xticks(rotation=45)

plt.tight_layout()
plt.suptitle('Diabetic Readmission Prediction: Model Comparison', fontsize=16, y=0.98)
plt.show()

# Step 8: Declare Winner
print(f"\n WINNER: {winner}")
print(f"   - AUC: {results_df.loc[winner, 'AUC']:.4f}")
print(f"   - F1: {results_df.loc[winner, 'F1']:.4f}")
print(f"   - Recall: {results_df.loc[winner, 'Recall']:.4f}")
print(f"   - Why? Best balance of detecting readmissions (high Recall) while avoiding false alarms (high Precision).")

#Not the final code

import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE
import warnings; warnings.filterwarnings('ignore')

# Load  original dataset
df = pd.read_csv('diabetic_data.csv', na_values='?')
print(f"Original shape: {df.shape}")

df = df[df.gender != 'Unknown/Invalid']
df['readmitted'] = (df['readmitted'] == '<30').astype(int)

df.drop(['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty'],
        axis=1, inplace=True, errors='ignore')

# Your original preprocessing
age_map = {'[0-10)':5,'[10-20)':15,'[20-30)':25,'[30-40)':35,'[40-50)':45,
           '[50-60)':55,'[60-70)':65,'[70-80)':75,'[80-90)':85,'[90-100)':95}
df['age'] = df['age'].map(age_map)

def simple_diag(x):
    try:
        v = float(x)
        if 390 <= v <= 459 or v == 785: return 'Circulatory'
        if 460 <= v <= 519 or v == 786: return 'Respiratory'
        if 520 <= v <= 579 or v == 787: return 'Digestive'
        if np.floor(v) == 250: return 'Diabetes'
        if 800 <= v <= 999: return 'Injury'
        if 140 <= v <= 239: return 'Neoplasms'
        return 'Other'
    except:
        return 'Other'

for c in ['diag_1','diag_2','diag_3']:
    df[c] = df[c].apply(simple_diag)

# Fill missing & encode
for col in df.select_dtypes('object').columns:
    df[col] = df[col].fillna('Missing')
le = LabelEncoder()
for col in df.select_dtypes('object').columns:
    df[col] = le.fit_transform(df[col].astype(str))

# Final data
X = df.drop('readmitted', axis=1)
y = df['readmitted']

print(f"Final shape: {df.shape} | Readmission rate: {y.mean():.3f}")

# Split + SMOTE + Scale
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
X_train_res, y_train_res = SMOTE(random_state=42).fit_resample(X_train, y_train)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)

print(f"After SMOTE: {X_train_res.shape} | Balance: {np.bincount(y_train_res)}")
print("Starting hyperparameter tuning for all 5 models...\n")

# Hyperparameter grids
param_grids = {
    'Logistic Regression': {'C': [0.1, 1, 10], 'penalty': ['l2'], 'solver': ['lbfgs', 'liblinear']},
    'Random Forest': {'n_estimators': [400, 600], 'max_depth': [12, 18, None], 'min_samples_leaf': [1, 3]},
    'XGBoost': {'n_estimators': [500, 700], 'max_depth': [6, 8], 'learning_rate': [0.05, 0.1], 'subsample': [0.8, 1.0]},
#    'LightGBM': {'n_estimators': [600, 800], 'learning_rate': [0.05, 0.1], 'num_leaves': [80, 128], 'max_depth': [8, 10]},
    'SVM (RBF)': {'C': [1, 10], 'gamma': ['scale', 0.01]}
}

# Base models
models = {
    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_jobs=-1),
    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', n_jobs=-1),
  #  'LightGBM': LGBMClassifier(random_state=42, verbosity=-1, n_jobs=-1),
    'SVM (RBF)': SVC(probability=True, random_state=42)
}

# Store results
results = []
best_models = {}
probs = {}
preds = {}

# Hyperparameter tuning loop
for name, model in models.items():
    print(f"→ Tuning {name:<18}", end="")
    search = RandomizedSearchCV(
        model, param_grids[name], n_iter=10 if 'SVM' not in name else 6,
        scoring='roc_auc', cv=3, random_state=42, n_jobs=-1
    )

    if name == 'SVM (RBF)':
        idx = np.random.choice(len(X_train_scaled), 25000, replace=False)
        search.fit(X_train_scaled[idx], y_train_res[idx])
    else:
        search.fit(X_train_scaled, y_train_res)

    best = search.best_estimator_
    prob = best.predict_proba(X_test_scaled)[:,1]
    pred = best.predict(X_test_scaled)

    best_models[name] = best
    probs[name] = prob
    preds[name] = pred

    results.append({
        'Model': name,
        'Accuracy': round(accuracy_score(y_test, pred), 4),
        'Precision': round(precision_score(y_test, pred), 4),
        'Recall': round(recall_score(y_test, pred), 4),
        'F1': round(f1_score(y_test, pred), 4),
        'AUC': round(roc_auc_score(y_test, prob), 4),
        'Best Params': search.best_params_
    })
    print(f"Done | AUC = {results[-1]['AUC']}")

# Final results table
results_df = pd.DataFrame(results).sort_values('AUC', ascending=False).reset_index(drop=True)
print("\n" + "="*85)
print("FINAL RESULTS - ALL 5 MODELS (HYPERPARAMETER TUNED)")
print("="*85)
print(results_df[['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']])

# Show best params
print("\nBEST HYPERPARAMETERS:")
for r in results:
    print(f"{r['Model']:20}: {r['Best Params']}")

# PLOTS
fig = plt.figure(figsize=(20, 16))

# 1. AUC Bar Chart (Winner in Gold)
ax1 = plt.subplot(3, 3, 1)
colors = ['gold' if i == 0 else 'skyblue' for i in range(len(results_df))]
results_df.plot(x='Model', y='AUC', kind='bar', ax=ax1, color=colors, legend=False)
ax1.set_title('AUC Comparison (Gold = Winner)', fontweight='bold', fontsize=14)
ax1.set_ylabel('AUC')

# 2. All Metrics
ax2 = plt.subplot(3, 3, 2)
metrics_plot = results_df.set_index('Model')[['Accuracy','Precision','Recall','F1','AUC']]
metrics_plot.plot(kind='bar', ax=ax2)
ax2.set_title('All Metrics')
ax2.legend(bbox_to_anchor=(1, 1))

# 3. ROC Curves
ax3 = plt.subplot(3, 3, 3)
for name, prob in probs.items():
    fpr, tpr, _ = roc_curve(y_test, prob)
    auc_val = results_df[results_df.Model == name]['AUC'].values[0]
    plt.plot(fpr, tpr, label=f"{name} ({auc_val})")
plt.plot([0,1],[0,1],'k--')
plt.title('ROC Curves'); plt.legend()

# 4. Confusion Matrices
for i, name in enumerate(best_models.keys(), 4):
    ax = plt.subplot(3, 3, i)
    cm = confusion_matrix(y_test, preds[name])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)
    auc_val = results_df[results_df.Model == name]['AUC'].values[0]
    ax.set_title(f"{name}\nAUC = {auc_val}")
    ax.set_xlabel('Predicted'); ax.set_ylabel('Actual')

plt.tight_layout()
plt.suptitle('DIABETIC READMISSION: FULL MODEL COMPARISON', fontsize=20, fontweight='bold', y=1.02)
plt.show()

# Winner
winner = results_df.iloc[0]
print(f"\nWINNER: {winner['Model']}")
print(f"        AUC       = {winner['AUC']:.4f}")
print(f"        Recall    = {winner['Recall']:.4f}")
print(f"        Precision = {winner['Precision']:.4f}")
print(f"        F1        = {winner['F1']:.4f}")
print(f"        Best Params: {winner['Best Params']}")

#not good for readmission class
#not the final code. ignore it.


import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, average_precision_score, classification_report,
                             confusion_matrix, roc_curve, precision_recall_curve)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings("ignore")

# ------------------ 1. YOUR ORIGINAL SMART PREPROCESSING ------------------
df = pd.read_csv("diabetic_data.csv", na_values="?", low_memory=False)

# Clean
df = df[df.gender != "Unknown/Invalid"]
df.drop(columns=["encounter_id", "patient_nbr", "weight", "payer_code", "medical_specialty",
                 "examide", "citoglipton"], errors="ignore", inplace=True)

# Target
df["readmitted"] = (df["readmitted"] == "<30").astype(int)

# Age → numeric
def age_mid(a):
    m = pd.Series(a).str.extract(r"\[(\d+)-(\d+)\)")
    return pd.to_numeric(m[0], errors='coerce').fillna(0) + 5

df["age_num"] = df["age"].apply(lambda x: age_mid(x))

# ICD-9 bucketing
def bucket_icd9(code):
    if pd.isna(code): return "missing"
    s = str(code)
    if s.startswith(("V", "E")): return s[0]
    try:
        v = float(s)
        if 390 <= v <= 459 or v == 785: return "circulatory"
        if 460 <= v <= 519 or v == 786: return "respiratory"
        if 520 <= v <= 579 or v == 787: return "digestive"
        if 250 <= v < 251: return "diabetes"
        if 800 <= v <= 999: return "injury"
        if 140 <= v <= 239: return "neoplasms"
        return "other"
    except:
        return "other"

for c in ["diag_1", "diag_2", "diag_3"]:
    df[f"{c}_cat"] = df[c].apply(bucket_icd9)

# Lab tests ordinal
df["max_glu_serum"] = df["max_glu_serum"].map({"None": 0, "Norm": 1, ">200": 2, ">300": 3}).fillna(0)
df["A1Cresult"] = df["A1Cresult"].map({"None": 0, "Norm": 1, ">7": 2, ">8": 3}).fillna(0)

# Fill race/specialty
df["race"] = df["race"].fillna("Other")

# Derived features
df["total_visits"] = df["number_outpatient"] + df["number_emergency"] + df["number_inpatient"]
df["meds_per_day"] = df["num_medications"] / (df["time_in_hospital"] + 1)

# Final X, y
drop_final = ["readmitted", "age", "diag_1", "diag_2", "diag_3"]
X = df.drop(columns=drop_final)
y = df["readmitted"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ------------------ 2. Preprocessing Pipeline (One-Hot + Scaling) ------------------
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder

num_cols = X.select_dtypes(include=["int64", "float64"]).columns.tolist()
cat_cols = X.select_dtypes(include=["object"]).columns.tolist()

num_pipe = Pipeline([("imputer", SimpleImputer(strategy="median")), ("scaler", StandardScaler())])
cat_pipe = Pipeline([("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
                     ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))])

preprocess = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
])

# Fit preprocess
X_train_proc = preprocess.fit_transform(X_train)
X_test_proc = preprocess.transform(X_test)

print(f"Preprocessed shape: {X_train_proc.shape}")
print(f"Readmission rate: {y.mean():.3f} → Positive class: {y.sum()} / {len(y)}")

# ------------------ 3. Models ------------------
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, class_weight="balanced", n_jobs=-1),
    "Random Forest": RandomForestClassifier(n_estimators=800, max_depth=None, min_samples_leaf=1,
                                            class_weight="balanced_subsample", random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(n_estimators=800, max_depth=8, learning_rate=0.05, subsample=0.8,
                             colsample_bytree=0.8, random_state=42, n_jobs=-1,
                             scale_pos_weight=(len(y_train)-y_train.sum())/y_train.sum()),
    "Linear SVM (Calibrated)": CalibratedClassifierCV(
        LinearSVC(class_weight="balanced", max_iter=10000), cv=3, method="sigmoid")
}

# ------------------ 4. Train & Individual Reports ------------------
results = []
plt.figure(figsize=(20, 28))

plot_idx = 1
for name, model in models.items():
    print(f"\n{'='*60}")
    print(f" TRAINING: {name.upper()}")
    print('='*60)

    model.fit(X_train_proc, y_train)
    pred = model.predict(X_test_proc)
    prob = model.predict_proba(X_test_proc)[:, 1]

    # Metrics
    acc = accuracy_score(y_test, pred)
    prec = precision_score(y_test, pred)
    rec = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    auc = roc_auc_score(y_test, prob)
    pr_auc = average_precision_score(y_test, prob)

    results.append({"Model": name, "AUC": auc, "PR-AUC": pr_auc, "Recall": rec,
                    "Precision": prec, "F1": f1, "Accuracy": acc})

    # --- Text Reports ---
    print(f"\nCLASSIFICATION REPORT - {name}")
    print(classification_report(y_test, pred, digits=4))

    cm = confusion_matrix(y_test, pred)
    print("CONFUSION MATRIX:")
    print(cm)
    print(f"  TN: {cm[0,0]:>6} | FP: {cm[0,1]:>6}")
    print(f"  FN: {cm[1,0]:>6} | TP: {cm[1,1]:>6}")

    # --- Plots ---
    # ROC
    fpr, tpr, _ = roc_curve(y_test, prob)
    plt.subplot(4, 4, plot_idx)
    plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}', lw=2, color="darkorange")
    plt.plot([0,1],[0,1],'k--')
    plt.title(f"{name}\nROC Curve", fontweight="bold")
    plt.xlabel("FPR"); plt.ylabel("TPR"); plt.legend()
    plot_idx += 1

    # PR Curve
    p, r, _ = precision_recall_curve(y_test, prob)
    plt.subplot(4, 4, plot_idx)
    plt.plot(r, p, label=f'PR-AUC = {pr_auc:.4f}', lw=2, color="green")
    plt.title(f"{name}\nPrecision-Recall Curve", fontweight="bold")
    plt.xlabel("Recall"); plt.ylabel("Precision"); plt.legend()
    plot_idx += 1

    # Confusion Matrix Heatmap
    plt.subplot(4, 4, plot_idx)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
                xticklabels=["No", "Yes"], yticklabels=["No", "Yes"])
    plt.title(f"{name}\nConfusion Matrix", fontweight="bold")
    plt.xlabel("Predicted"); plt.ylabel("Actual")
    plot_idx += 1

    # Metrics Summary Box
    plt.subplot(4, 4, plot_idx)
    plt.text(0.5, 0.8, f"AUC     : {auc:.4f}", ha="center", fontsize=14, fontweight="bold")
    plt.text(0.5, 0.6, f"PR-AUC  : {pr_auc:.4f}", ha="center", fontsize=12)
    plt.text(0.5, 0.4, f"Recall  : {rec:.4f}", ha="center", fontsize=12)
    plt.text(0.5, 0.2, f"F1      : {f1:.4f}", ha="center", fontsize=12)
    plt.title(f"{name}\nKey Metrics", fontweight="bold")
    plt.axis("off")
    plot_idx += 1

plt.suptitle("DIABETES READMISSION: FULL INDIVIDUAL MODEL ANALYSIS",
             fontsize=24, fontweight="bold", y=0.98)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# ------------------ 5. Final Ranking ------------------
results_df = pd.DataFrame(results).round(4)
results_df = results_df.sort_values("AUC", ascending=False).reset_index(drop=True)
results_df.index += 1

print("\n" + "="*100)
print(" " * 35 + "FINAL RANKING BY AUC (Your Method)")
print("="*100)
print(results_df.to_string(index=True))
print("="*100)

winner = results_df.iloc[0]
print(f"\nWINNER: {winner['Model']}")
print(f"        AUC        = {winner['AUC']:.4f}")
print(f"        Recall     = {winner['Recall']:.4f}")
print(f"        Precision  = {winner['Precision']:.4f}")
print(f"        F1-Score   = {winner['F1']:.4f}")

# not the final code. ignore it

import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
import warnings; warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    average_precision_score, roc_curve, precision_recall_curve
)

# ------------------- RareCategoryGrouper -------------------
class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    def __init__(self, min_freq=50):
        self.min_freq = min_freq
        self.frequent_maps_ = {}
        self.columns_ = []

    def fit(self, X, y=None):
        X = pd.DataFrame(X)
        self.columns_ = X.columns.tolist()
        for c in self.columns_:
            vc = X[c].astype(str).value_counts(dropna=False)
            self.frequent_maps_[c] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        X = pd.DataFrame(X, columns=self.columns_) if not isinstance(X, pd.DataFrame) else X.copy()
        for c in self.columns_:
            keep = self.frequent_maps_[c]
            X[c] = X[c].astype(str).where(X[c].astype(str).isin(keep), "RARE")
        return X

# ------------------- Load & Preprocess -------------------
df = pd.read_csv("diabetic_data.csv", na_values="?", low_memory=False)

# Clean
df = df[df.gender != "Unknown/Invalid"].copy()
df.drop(columns=["encounter_id", "patient_nbr", "weight", "payer_code", "examide", "citoglipton"],
        errors="ignore", inplace=True)

# TARGET: ANY READMISSION AT ALL (most clinically useful)
df["readmitted_any"] = (df["readmitted"] != "NO").astype(int)
print(f"Any readmission rate: {df['readmitted_any'].mean():.1%}")

# Age → midpoint
def age_mid(x):
    m = re.match(r"\[(\d+)-(\d+)\)", str(x))
    return (int(m.group(1)) + int(m.group(2))) / 2 if m else np.nan
df["age_num"] = df["age"].apply(age_mid)

# ICD-9 buckets
def bucket_icd9(code):
    if pd.isna(code): return "missing"
    s = str(code).strip()
    if s.startswith(("V","E")): return s[0].lower()
    try: v = float(s)
    except: return "other"
    if 390 <= v <= 459 or v == 785: return "circulatory"
    if 460 <= v <= 519 or v == 786: return "respiratory"
    if 520 <= v <= 579 or v == 787: return "digestive"
    if 250 <= v < 251: return "diabetes"
    if 800 <= v <= 999: return "injury"
    if 140 <= v <= 239: return "neoplasms"
    return "other"

for c in ["diag_1", "diag_2", "diag_3"]:
    df[f"{c}_bucket"] = df[c].apply(bucket_icd9)

# Lab tests ordinal
df["max_glu_serum"] = df["max_glu_serum"].map({"None":0, "Norm":1, ">200":2, ">300":3}).fillna(0)
df["A1Cresult"] = df["A1Cresult"].map({"None":0, "Norm":1, ">7":2, ">8":3}).fillna(0)

# Fill race
df["race"] = df["race"].fillna("Other")

# Your killer features
df["total_visits"] = df["number_outpatient"] + df["number_emergency"] + df["number_inpatient"]
df["meds_per_day"] = df["num_medications"] / (df["time_in_hospital"] + 1)

# Final X, y
X = df.drop(columns=["readmitted", "readmitted_any", "age", "diag_1", "diag_2", "diag_3"])
y = df["readmitted_any"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ------------------- Preprocessing -------------------
num_cols = X.select_dtypes("number").columns.tolist()
cat_cols = X.select_dtypes("object").columns.tolist()

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median"))])
cat_pipe = Pipeline([
    ("rare", RareCategoryGrouper(min_freq=50)),
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

preprocess = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
], verbose_feature_names_out=False)

# ------------------- Models (All Winners) -------------------
models = {
    "Random Forest": RandomForestClassifier(n_estimators=1000, max_features=0.4, n_jobs=-1, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=1000, max_depth=8, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9,
                             random_state=42, n_jobs=-1),
    "LightGBM": LGBMClassifier(n_estimators=1000, max_depth=12, learning_rate=0.05, num_leaves=200,
                               subsample=0.9, colsample_bytree=0.9, random_state=42, verbose=-1),
    "CatBoost": CatBoostClassifier(iterations=1200, depth=8, learning_rate=0.05, random_seed=42, verbose=False),
    "Logistic Regression": LogisticRegression(max_iter=1000, n_jobs=-1)
}

# ------------------- Train & Evaluate -------------------
results = []
plt.figure(figsize=(20, 28))
plot_idx = 1

for name, model in models.items():
    print(f"\n{'='*100}")
    print(f" TRAINING: {name.upper():^96}")
    print('='*100)

    pipe = Pipeline([("prep", preprocess), ("clf", model)])
    pipe.fit(X_train, y_train)

    pred = pipe.predict(X_test)
    prob = pipe.predict_proba(X_test)[:, 1]

    auc = roc_auc_score(y_test, prob)
    pr_auc = average_precision_score(y_test, prob)
    report = classification_report(y_test, pred, output_dict=True)
    cm = confusion_matrix(y_test, pred)

    results.append({
        "Model": name,
        "AUC": round(auc, 4),
        "PR-AUC": round(pr_auc, 4),
        "Recall": round(report["1"]["recall"], 4),
        "Precision": round(report["1"]["precision"], 4),
        "F1": round(report["1"]["f1-score"], 4),
        "TP": cm[1,1]
    })

    print(f"\nCLASSIFICATION REPORT — {name}")
    print(classification_report(y_test, pred, digits=4))
    print("Confusion Matrix:\n", cm)

    # Plots
    fpr, tpr, _ = roc_curve(y_test, prob)
    plt.subplot(5, 4, plot_idx); plot_idx += 1
    plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}', lw=3)
    plt.plot([0,1],[0,1],'k--'); plt.title(f"{name}\nROC", fontweight="bold"); plt.legend()

    prec, rec, _ = precision_recall_curve(y_test, prob)
    plt.subplot(5, 4, plot_idx); plot_idx += 1
    plt.plot(rec, prec, label=f'PR-AUC = {pr_auc:.4f}', lw=3, color="green")
    plt.title(f"{name}\nPR Curve", fontweight="bold"); plt.legend()

    plt.subplot(5, 4, plot_idx); plot_idx += 1
    sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", cbar=False)
    plt.title(f"{name}\nConfusion Matrix", fontweight="bold")

plt.suptitle("PREDICTING ANY DIABETES READMISSION — 2025 SOTA", fontsize=28, fontweight="bold", y=0.98)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# ------------------- Final Ranking -------------------
results_df = pd.DataFrame(results).sort_values("AUC", ascending=False).reset_index(drop=True)
results_df.index += 1

print("\n" + "="*130)
print(" " * 50 + "FINAL RANKING — ANY READMISSION")
print("="*130)
print(results_df.to_string(index=True))
print("="*130)

winner = results_df.iloc[0]
print(f"\nCHAMPION: {winner['Model']}")
print(f"         AUC           = {winner['AUC']:.4f}")
print(f"         Recall        = {winner['Recall']:.4f}  →  catches {winner['Recall']*100:.1f}% of ALL readmissions")
print(f"         F1-Score      = {winner['F1']:.4f}")
print(f"         True Positives = {winner['TP']:,}")
#print("\nThis model can save hospitals millions by identifying nearly every patient who will return.")

"""#Ali Tahririan - Applied one-hot encoding to all categorical features, scaled numeric columns with StandardScaler, imputed missing values using SimpleImputer, removed ID and low-value columns (encounter_id, patient_nbr, weight, payer_code). Used 80:20 train–test split with class_weight='balanced'.Tuned C ∈ {0.01, 0.1, 1, 10} using HalvingGridSearchCV (best C = 0.1, penalty = 'l2'). Accuracy = 64.1 %, F1 = 61.3 %, ROC-AUC = 0.70.

"""



"""## Logistic Regression"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay,
    classification_report, confusion_matrix
)

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"   # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)

DROP_COLS = ['weight','max_glu_serum','A1Cresult','payer_code','encounter_id','patient_nbr']

# ---------------- Load & Clean ----------------
df = pd.read_csv(DATA_PATH, na_values='?', low_memory=False)
assert 'readmitted' in df.columns, "Target 'readmitted' not found."

for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)

for c in ['race', 'medical_specialty']:
    if c in df.columns:
        df[c] = df[c].fillna('other')

# Target binary: readmitted != 'NO'
y = (df['readmitted'].astype(str).str.upper() != 'NO').astype(int)
X = df.drop(columns=['readmitted']).copy()

# ---------------- Columns ----------------
num_cols = [c for c in [
    'time_in_hospital','num_lab_procedures','num_procedures','num_medications',
    'number_outpatient','number_emergency','number_inpatient','number_diagnoses'
] if c in X.columns]
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# ---------------- Preprocessing ----------------
ordinal_enc = OrdinalEncoder(
    handle_unknown="use_encoded_value", unknown_value=-1, dtype=np.float64
)

num_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())  # important for logistic regression
])

cat_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("enc", ordinal_enc)
])

preproc = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
])

# ---------------- Model: Logistic Regression ----------------
log_reg = LogisticRegression(
    max_iter=1000,
    solver='lbfgs',
    class_weight='balanced',
    random_state=SEED
)

pipe = Pipeline([
    ("prep", preproc),
    ("clf", log_reg),
])

# ---------------- Train ----------------
print("\nTraining Logistic Regression ...")
pipe.fit(X_train, y_train)

# ---------------- Evaluate ----------------
proba = pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "precision": precision_score(y_test, pred),
    "recall": recall_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (Logistic Regression) ===")
for k, v in metrics.items():
    print(f"{k:>10}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
RocCurveDisplay.from_estimator(pipe, X_test, y_test, name="LogReg")
plt.title("ROC — Logistic Regression (Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_roc.png"), dpi=160)
plt.show()

PrecisionRecallDisplay.from_estimator(pipe, X_test, y_test, name="LogReg")
plt.title("Precision–Recall — Logistic Regression (Test)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_pr.png"), dpi=160)
plt.show()

# ---------------- Coefficients ----------------
feat_names = num_cols + cat_cols
coef = pipe.named_steps["clf"].coef_[0]
feat_imp = pd.DataFrame({"feature": feat_names, "coefficient": coef})
feat_imp["abs_coef"] = feat_imp["coefficient"].abs()
feat_imp = feat_imp.sort_values("abs_coef", ascending=False).head(20)

print("\nTop 20 features by absolute coefficient magnitude:")
print(feat_imp[["feature", "coefficient"]])

plt.figure()
plt.barh(feat_imp["feature"][::-1], feat_imp["coefficient"][::-1])
plt.xlabel("Coefficient")
plt.title("Logistic Regression — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_top20_coeff.png"), dpi=160)
plt.show()

# ---------------- Save ----------------
joblib.dump(pipe, os.path.join(ARTIFACT_DIR, "logreg_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "logreg_metrics.csv"), index=False)
feat_imp.to_csv(os.path.join(ARTIFACT_DIR, "logreg_top20_coeff.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

"""## Logistic Regression Classifier"""

import os, re, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt
from typing import Dict

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score,
    RocCurveDisplay, PrecisionRecallDisplay, classification_report, confusion_matrix
)
from sklearn.experimental import enable_halving_search_cv  # noqa: F401
from sklearn.model_selection import HalvingGridSearchCV

# ---------------- Config ----------------
SEED = 42
np.random.seed(SEED)
DATA_PATH = "diabetic_data.csv"  # change if needed
ARTIFACT_DIR = "artifacts"; os.makedirs(ARTIFACT_DIR, exist_ok=True)
CACHE_DIR = "skcache"; os.makedirs(CACHE_DIR, exist_ok=True)

DROP_COLS = ["encounter_id", "patient_nbr", "weight", "payer_code", "examide", "citoglipton"]

# ---------------- Helpers ----------------
def age_mid(a):
    """Convert age bracket like '[70-80)' -> 75.0"""
    if pd.isna(a): return np.nan
    m = re.match(r"\[(\d+)-(\d+)\)", str(a))
    return np.nan if not m else (int(m.group(1))+int(m.group(2)))/2

def bucket_icd9(code: str) -> str:
    """Broad ICD-9 buckets to reduce category explosion."""
    if pd.isna(code): return "icd_missing"
    s = str(code).strip()
    if s.startswith("V"): return "icd_V"
    if s.startswith("E"): return "icd_E"
    try: v = float(s)
    except ValueError: return "icd_other"
    if 390 <= v <= 459 or v == 785: return "circulatory"
    if 460 <= v <= 519 or v == 786: return "respiratory"
    if 520 <= v <= 579 or v == 787: return "digestive"
    if 250 <= v < 251:             return "diabetes_specific"
    if 800 <= v <= 999:            return "injury"
    if 710 <= v <= 739:            return "musculoskeletal"
    if 580 <= v <= 629 or v == 788:return "genitourinary"
    if 140 <= v <= 239:            return "neoplasms"
    return "other"

class RareCategoryGrouper(BaseEstimator, TransformerMixin):
    """Group infrequent categories to 'RARE' (fit on train only)."""
    def __init__(self, min_freq: int = 50):
        self.min_freq = min_freq
        self.frequent_maps_: Dict[str, set] = {}
        self.columns_: list = []

    def fit(self, X: pd.DataFrame, y=None):
        if not isinstance(X, pd.DataFrame):
            raise TypeError("RareCategoryGrouper expects a pandas DataFrame.")
        self.columns_ = X.columns.tolist()
        self.frequent_maps_ = {}
        for c in self.columns_:
            vc = X[c].astype(str).value_counts(dropna=False)
            self.frequent_maps_[c] = set(vc[vc >= self.min_freq].index)
        return self

    def transform(self, X):
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X, columns=self.columns_)
        Xo = X.copy()
        for c in self.columns_:
            keep = self.frequent_maps_[c]
            Xo[c] = Xo[c].astype(str).where(Xo[c].astype(str).isin(keep), "RARE")
        return Xo

# ---------------- Load ----------------
df = pd.read_csv(DATA_PATH, na_values="?", low_memory=False)
assert "readmitted" in df.columns, "Target 'readmitted' not found."
df.drop_duplicates(inplace=True)
for c in DROP_COLS:
    if c in df.columns:
        df.drop(columns=c, inplace=True)
for c in ["race", "medical_specialty"]:
    if c in df.columns:
        df[c] = df[c].fillna("other")

# Ordinal mapping for glu/A1C
glu_map = {"None": 0, "Norm": 1, ">200": 2, ">300": 3}
a1c_map = {"None": 0, "Norm": 1, ">7": 2, ">8": 3}
if "max_glu_serum" in df.columns:
    df["max_glu_serum"] = df["max_glu_serum"].map(glu_map).astype("float64")
if "A1Cresult" in df.columns:
    df["A1Cresult"] = df["A1Cresult"].map(a1c_map).astype("float64")

# Target
y = (df["readmitted"].astype(str).str.upper() != "NO").astype(int)
X = df.drop(columns=["readmitted"]).copy()

# Feature engineering
if "age" in X.columns:
    X["age_num"] = X["age"].apply(age_mid).astype("float64")
for d in ["diag_1", "diag_2", "diag_3"]:
    if d in X.columns:
        X[f"{d}_bucket"] = X[d].apply(bucket_icd9)
if set(["number_outpatient","number_emergency","number_inpatient"]).issubset(X.columns):
    X["util_visits"] = (X["number_outpatient"].fillna(0) +
                        X["number_emergency"].fillna(0) +
                        X["number_inpatient"].fillna(0)).astype("float64")
if set(["num_medications","time_in_hospital"]).issubset(X.columns):
    X["meds_per_day"] = (X["num_medications"].astype("float64") /
                         (X["time_in_hospital"].astype("float64") + 1.0))

# Columns
likely_numeric = [
    "time_in_hospital","num_lab_procedures","num_procedures","num_medications",
    "number_outpatient","number_emergency","number_inpatient","number_diagnoses",
    "age_num","A1Cresult","max_glu_serum","util_visits","meds_per_day"
]
num_cols = [c for c in likely_numeric if c in X.columns]
cat_cols = [c for c in X.columns if c not in num_cols]
drop_single = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]
if drop_single:
    X.drop(columns=drop_single, inplace=True)
    num_cols = [c for c in num_cols if c not in drop_single]
    cat_cols = [c for c in cat_cols if c not in drop_single]

print("Numeric:", num_cols)
print("Categorical:", cat_cols)

# ---------------- Split ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED, stratify=y
)

# ---------------- Preprocessing ----------------
cat_pipe = Pipeline(steps=[
    ("rare", RareCategoryGrouper(min_freq=50)),
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

num_pipe = Pipeline(steps=[
    ("imp", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

preproc = ColumnTransformer(
    transformers=[
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols),
    ],
    remainder="drop",
    verbose_feature_names_out=False
)

# ---------------- Model ----------------
logreg = LogisticRegression(
    max_iter=1000,
    solver="lbfgs",
    class_weight="balanced",
    n_jobs=-1,
    random_state=SEED
)

pipe = Pipeline(steps=[
    ("prep", preproc),
    ("clf", logreg)
])

# ---------------- Light tuning ----------------
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)
param_grid = {
    "clf__C": [0.01, 0.1, 1.0, 10],
    "clf__penalty": ["l2"]
}

search = HalvingGridSearchCV(
    estimator=pipe,
    param_grid=param_grid,
    factor=3,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    verbose=1,
    refit=True
)

print("\nSearching Logistic Regression …")
search.fit(X_train, y_train)
print("Best params:", search.best_params_, "| Best CV AUC:", round(search.best_score_, 4))
best_pipe = search.best_estimator_

# ---------------- Evaluate ----------------
proba = best_pipe.predict_proba(X_test)[:, 1]
pred  = (proba >= 0.5).astype(int)

metrics = {
    "accuracy": accuracy_score(y_test, pred),
    "precision": precision_score(y_test, pred),
    "recall": recall_score(y_test, pred),
    "f1": f1_score(y_test, pred),
    "roc_auc": roc_auc_score(y_test, proba),
    "pr_auc": average_precision_score(y_test, proba),
}
print("\n=== Test metrics (Logistic Regression, tuned) ===")
for k, v in metrics.items():
    print(f"{k:>10}: {v:.4f}")

print("\nConfusion Matrix (rows=true, cols=pred):")
print(confusion_matrix(y_test, pred))
print("\nClassification Report:")
print(classification_report(y_test, pred, digits=4))

# ---------------- Visuals ----------------
RocCurveDisplay.from_estimator(best_pipe, X_test, y_test, name="LogReg (tuned)")
plt.title("ROC — Logistic Regression (Tuned)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_tuned_roc.png"), dpi=160)
plt.show()

PrecisionRecallDisplay.from_estimator(best_pipe, X_test, y_test, name="LogReg (tuned)")
plt.title("Precision–Recall — Logistic Regression (Tuned)")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_tuned_pr.png"), dpi=160)
plt.show()

# ---------------- Coefficients ----------------
def get_feature_names(prep: ColumnTransformer):
    names = []
    names.extend(prep.transformers_[0][2])  # numeric
    ohe = prep.named_transformers_["cat"].named_steps["ohe"]
    cat_input = prep.transformers_[1][2]
    ohe_names = ohe.get_feature_names_out(cat_input).tolist()
    names.extend(ohe_names)
    return names

feat_names = get_feature_names(best_pipe.named_steps["prep"])
coef = best_pipe.named_steps["clf"].coef_[0]
coef_df = (pd.DataFrame({"feature": feat_names, "coefficient": coef})
           .assign(abs_coef=lambda d: d["coefficient"].abs())
           .sort_values("abs_coef", ascending=False)
           .head(20))

print("\nTop 20 features by absolute coefficient magnitude:")
print(coef_df[["feature", "coefficient"]])

plt.figure()
plt.barh(coef_df["feature"][::-1], coef_df["coefficient"][::-1])
plt.xlabel("Coefficient")
plt.title("Logistic Regression (Tuned) — Top 20 Features")
plt.tight_layout()
plt.savefig(os.path.join(ARTIFACT_DIR, "logreg_tuned_top20_coeff.png"), dpi=160)
plt.show()

# ---------------- Save ----------------
joblib.dump(best_pipe, os.path.join(ARTIFACT_DIR, "logreg_tuned_pipeline.joblib"))
pd.DataFrame([metrics]).to_csv(os.path.join(ARTIFACT_DIR, "logreg_tuned_metrics.csv"), index=False)
coef_df.to_csv(os.path.join(ARTIFACT_DIR, "logreg_tuned_top20_coeff.csv"), index=False)

print(f"\nArtifacts saved to: {os.path.abspath(ARTIFACT_DIR)}")

"""# XG BOOST Group preprocessing

"""

# XGBOOST MODEL (no preprocessing)
import xgboost as xgb
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

df = data_clean.copy()


# FEATURE / TARGET SPLIT

y = df["readmitted"]
X = df.drop(columns=["readmitted"])


# TRAIN / TEST SPLIT

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


# CONVERT TO DMATRIX FOR XGBOOST

dtrain = xgb.DMatrix(X_train, label=y_train)
dtest  = xgb.DMatrix(X_test,  label=y_test)

# PARAMETER SETUP & TRAINING

xgb_params = {
    "objective":"multi:softmax",
    "num_class": y.nunique(),         # uses # of values inside readmitted
    "eval_metric": "mlogloss",
    "learning_rate": 0.1,
    "max_depth": 4,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": 42
}

final_model = xgb.train(
    params=xgb_params,
    dtrain=dtrain,
    num_boost_round=300,
    evals=[(dtest,"Validation")],
    early_stopping_rounds=20,
    verbose_eval=True
)


# 5. EVALUATION

y_pred = final_model.predict(dtest)
print("Model Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""#XG BOOST Madi's Preprocessing"""

## 1️⃣ Preprocessing + Feature Engineering
!pip install --upgrade xgboost

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# Copy data_clean to XG_clean
XG_clean = data_clean.copy()

# Drop ID columns
id_cols = ['patient_id', 'encounter_id']  # adjust if your dataset has other ID columns
for col in id_cols:
    if col in XG_clean.columns:
        XG_clean.drop(col, axis=1, inplace=True)

# Ensure numeric (already label-encoded, but double-check)
XG_clean = XG_clean.apply(pd.to_numeric, errors='coerce').fillna(0)

# Optional: you could consider dropping 'race' or 'gender' later if they hurt performance
# But we keep them for now as they may help predict readmission

print("✅ Preprocessing & feature engineering complete. Dataset shape:", XG_clean.shape)

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import pandas as pd

# Make a copy first
XG_clean = data_clean.copy()

# Encode target
le = LabelEncoder()
XG_clean['readmitted_encoded'] = le.fit_transform(XG_clean['readmitted'])

# Split features & target
X = XG_clean.drop(['readmitted', 'readmitted_encoded'], axis=1)  # drop original target
y = XG_clean['readmitted_encoded']

# One-hot encode categorical features
categorical_cols = X.select_dtypes(include='object').columns
X = pd.get_dummies(X, columns=categorical_cols)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Handle class imbalance with SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print("Original training set shape:", y_train.value_counts().to_dict())
print("After SMOTE resampling:", y_train_res.value_counts().to_dict())

# Sanitize column names (replace invalid chars for XGBoost)
X_train_res.columns = X_train_res.columns.str.replace(r"[^0-9a-zA-Z_]", "_", regex=True)
X_test.columns = X_test.columns.str.replace(r"[^0-9a-zA-Z_]", "_", regex=True)

# Train quick baseline XGBoost to get feature importances
baseline_model = XGBClassifier(
    n_estimators=100,
    max_depth=4,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1,
    eval_metric='mlogloss'
)
baseline_model.fit(X_train_res, y_train_res)

# Get feature importance
importances = pd.Series(baseline_model.feature_importances_, index=X_train_res.columns)
importances.sort_values(ascending=False, inplace=True)

print("Top 10 features by importance:")
print(importances.head(10))

# Remove features with < 5% importance
threshold = 0.05
low_importance_features = importances[importances < threshold].index.tolist()

if low_importance_features:
    print(f"\nDropping {len(low_importance_features)} low-importance features:")
    print(low_importance_features)
    XG_clean = XG_clean.drop(columns=low_importance_features)
else:
    print("\nNo features below importance threshold. Nothing dropped.")

# Convert training and test sets to DMatrix format
dtrain = xgb.DMatrix(X_train_res, label=y_train_res)
dtest = xgb.DMatrix(X_test, label=y_test)

# Default parameters for multi-class XGBoost
xgb_params = {
    'objective': 'multi:softmax',    # multi-class classification
    'num_class': len(y.unique()),    # number of classes
    'eval_metric': 'mlogloss',
    'learning_rate': 0.1,
    'max_depth': 4,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42
}

# Train model with early stopping
final_model = xgb.train(
    params=xgb_params,
    dtrain=dtrain,
    num_boost_round=400,             # maximum number of trees
    evals=[(dtest, "test")],         # validation set for early stopping
    early_stopping_rounds=25,        # stop if no improvement after 25 rounds
    verbose_eval=True
)

# 9️⃣ Evaluate model (use DMatrix)
y_pred = final_model.predict(dtest).astype(int)

print("\n✅ Final Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\n📊 Classification Report:\n", classification_report(y_test, y_pred, digits=4))

"""# Hye Eun SVC vs. LightGBM:

**SVC:**
* Mapped ages by median (ie. range 0-10 becomes 5)
* Filled missing data in diag_1, diag_2, diag_3 with 'missing'
  * Created 20 categories for icd 9 codes by mapping
* Only encoded target (as discussed) and binary features
* One hot encoded categorical columns
* Scaled numeric columns
* Trained with LinearSVC
  * with max_iter = 10000, tol = 0.01

**Macro F1 Score:**
* 0.4425

**Confusion Matrix:**
* [[8359  545 2069]

  [1066  381  825]

  [3805  540 2764]
--------------
**SVM**
* Same preprocessing steps as above.
* Tried PCA for dimensional reduction
  * Even trying max_iter = 10000, tol = 0.01, model is very slow.
  * Could try to tweak C or reduce training size set to maybe 20,000 with statified sampling (to preserve class ratios)

**Ultimately, computational load too heavy and model did not load**

---


**LightGBM**
* Same preprocessing steps except:
  * No one hot encoding - all object columns into categorical
* best observed parameters: learning_rate = 0.03, num_leaves = 63, min_data_in_leaf = 20, n_estimators = 1500

**Accuracy**
* 59.291%

**Macro F1 Score:**
* 0.550

**Confusion Matrix:**
* [[9174   33 1766]

  [1275  103  894]

  [4264   54 2791]

# SVC
"""

#---------------------------------------------------Imports----------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.svm import LinearSVC
from sklearn.metrics import f1_score, confusion_matrix

data = pd.read_csv('diabetic_data.csv', na_values='?')


#------------------------------------------------Preprocessing-----------------------------------------------------------

# Same as discussed (drop unnecessary columns and fill missing values with 'other')
data.drop(columns=['weight' , 'max_glu_serum', 'A1Cresult','payer_code','encounter_id',	'patient_nbr'], inplace=True)

data['race'] = data['race'].fillna('other')
data['medical_specialty'] = data['medical_specialty'].fillna('other')

# Map ages (obj) by median to ensure ordinance
age_map = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35,
           '[40-50)': 45, '[50-60)': 55, '[60-70)': 65, '[70-80)': 75,
           '[80-90)': 85, '[90-100)': 95}
data['age'] = data['age'].map(age_map)


#-------Dealing with the diagnoses codes (diag_1, diag_2, diag_3)--------
# Fill missing diagnoses codes as 'missing' for diag_1, diag_2, diag_3
all3_diag = ['diag_1', 'diag_2', 'diag_3']
data[all3_diag] = data[all3_diag].fillna('missing')

# Map for diagnoses codes
# Necessary for one hot encoding to occur in following block
def map_diagnoses(icd_9):
'''Categorizes diagnosis code into one of the 20 following categories'''

    if icd_9 == 'missing':
        return 'missing'

    try:
        if icd_9[0] in ('E', 'V'):
            return 'External causes of injury/supplemental classification'

        code = float(icd_9)
        if 1 <= icd_9 <=139:
            return 'Infectious/Parasitic Disease'
        elif 140 <= icd_9 <= 239:
            return 'Neoplasm'
        elif 240 <= icd_9 <= 279:
            return 'Endocrine, Nutritional, Metabolic, or Immunity Disorder'
        elif 280 <= icd_9 <= 289:
            return 'Disease of blood/blood-forming organs'
        elif 290 <= icd_9 <= 319:
            return 'Mental Disorder'
        elif 320 <= icd_9 <= 289:
            return 'Nervous System Disease'
        elif 390 <= icd_9 <= 459:
            return 'Circulatory Disease'
        elif 460 <= icd_9 <= 519:
            return 'Respiratory Disease'
        elif 520 <= icd_9 <= 579:
            return 'Digestive System Disease'
        elif 580 <= icd_9 <= 629:
            return 'Genitourinary Disease'
        elif 630 <= icd_9 <= 679:
            return 'Complications of pregnancy, childbirth, or puerperium'
        elif 680 <= icd_9 <= 709:
            return 'Skin Diseases'
        elif 710 <= icd_9 <= 739:
            return 'Musculoskeletal/Connective Tissue Disease'
        elif 740 <= icd_9 <= 759:
            return 'Congenital Anomaly'
        elif 760 <= icd_9 <= 779:
            return 'Perinatal Conditions'
        elif 780 <= icd_9 <= 799:
            return 'Symptoms, signs, or ill-defined conditions'
        elif 800 <= icd_9 <= 999:
            return 'Injury or poisoning'
        else:
            return 'Other'

    except (IndexError, ValueError, TypeError):
            return 'Other'

for col in all3_diag:
    data[col] = data[col].apply(map_diagnoses)


#--------------Encode target and binary features----------------
# Encode readmitted (as previously discussed)
data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == '<30' else (2 if x == '>30' else 0))

# Encode diabetesMed and change
data['diabetesMed'] = data['diabetesMed'].map({'No': 0, 'Yes': 1})

data['change'] = data['change'].map({'No': 0, 'Yes': 1})


#-----------One Hot Encode Categorical/Nominal Columns-------------
# One hot encode to preseve these features' distinctness (no order)
nominal_cols = categorical_cols = data.select_dtypes(include=['object', 'int64']).columns.tolist()

# These columns will be excludedd since:
#   1. 'age' already processed above
#   2. true ordinal
exclude_cols = ['age', 'time_in_hospital', 'num_lab_procedures', 'num_procedures',
                'num_medications', 'number_outpatient', 'number_emergency',
                'number_inpatient', 'number_diagnoses', 'diabetesMed', 'readmitted']

#Convert to set for subtraction
nominal_set = set(nominal_cols)
exclude_set = set(exclude_cols)

ohe_col_set = nominal_set - exclude_set
ohe_col = list(ohe_col_set)

data_cleaned = pd.get_dummies(data, columns = ohe_col, drop_first = True)

# Check to make sure all features have been converted
remaining_objects = data_cleaned.select_dtypes(include='object').columns.tolist()

print('Remaining object columns:', remaining_objects)


#-------------------------------------------------Define X and y then split------------------------------------------------
X = data_cleaned.drop(columns = 'readmitted')
y = data_cleaned['readmitted']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)

#--------------------------------------------------Scale numeric features--------------------------------------------------
# ('diabetesMed' and 'readmitted' omitted)

numeric_features = ['age', 'time_in_hospital', 'num_lab_procedures', 'num_procedures',
                      'num_medications', 'number_outpatient', 'number_emergency',
                      'number_inpatient', 'number_diagnoses']

scale_numeric = StandardScaler()

# Clean up for missing values in the one hot encoded features
ohe_impute = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)

# Scale numeric features and impute the rest with ohe_impute
preprocessing = ColumnTransformer(
    transformers=[
        ('num_scaler', scale_numeric, numeric_features)
    ],
    remainder=ohe_impute
)

X_train_scaled = preprocessing.fit_transform(X_train)
X_test_scaled = preprocessing.transform(X_test)

#--------------------------------------------------Create and train model--------------------------------------------------
# LinearSVC works
svc = LinearSVC(
    C=1.0,
    class_weight='balanced',
    random_state=42,
    max_iter=10000,
    tol=0.01
)

svc.fit(X_train_scaled, y_train)

# # Trying SVM
# # PCA for dimensional reduction
# from sklearn.decomposition import PCA
# pca = PCA(n_components=0.95, random_state=42)

# X_train_pca = pca.fit_transform(X_train_scaled)
# X_test_pca = pca.transform(X_test_scaled)

# # Even trying max_iter = 10000, tol = 0.01, model is very slow.
# # Could try to tweak C or reduce training size set to maybe 20,000 with statified sampling (to preserve class ratios)
# svm = SVC(kernel = 'rbf', C = 1.0, gamma = 'scale', class_weight = 'balanced', random_state = 42, probability = False, max_iter = -1)

#-----------------------------------------------------Predictions and evaluation-------------------------------------------
y_pred = svc.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average = 'macro')
confusion_matrix = confusion_matrix(y_test, y_pred)

print('Accuracy:', accuracy)
print('Macro F1 Score:', f1_macro)
print('Confusion Matrix:\n', confusion_matrix)

"""# LightGBM"""



#---------------------------------------------------Imports----------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.utils.class_weight import compute_class_weight                       # new
import lightgbm as lgb
from lightgbm import LGBMClassifier                                            # scikit-learn wrapper
import warnings
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

data = pd.read_csv('diabetic_data.csv', na_values='?')


#------------------------------------------------Preprocessing-------------------------------------------------------------

# Same as discussed (drop unnecessary columns and fill missing values with 'other')
data.drop(columns=['weight' , 'max_glu_serum', 'A1Cresult','payer_code','encounter_id',	'patient_nbr'], inplace=True)

data['race'] = data['race'].fillna('other')
data['medical_specialty'] = data['medical_specialty'].fillna('other')

# Map ages (obj) by median to ensure ordinance
age_map = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35,
           '[40-50)': 45, '[50-60)': 55, '[60-70)': 65, '[70-80)': 75,
           '[80-90)': 85, '[90-100)': 95}
data['age'] = data['age'].map(age_map)


#-------Dealing with the diagnoses codes (diag_1, diag_2, diag_3)--------
# Fill missing diagnoses codes as 'missing' for diag_1, diag_2, diag_3
all3_diag = ['diag_1', 'diag_2', 'diag_3']
data[all3_diag] = data[all3_diag].fillna('missing')

# Map for diagnoses codes
# Necessary for one hot encoding to occur in following block
def map_diagnoses(icd_9):
  if icd_9 == 'missing':
    return 'missing'

    try:
        if icd_9[0] in ('E', 'V'):
            return 'External causes of injury/supplemental classification'

        code = float(icd_9)
        if 1 <= icd_9 <=139:
            return 'Infectious/Parasitic Disease'
        elif 140 <= icd_9 <= 239:
            return 'Neoplasm'
        elif 240 <= icd_9 <= 279:
            return 'Endocrine, Nutritional, Metabolic, or Immunity Disorder'
        elif 280 <= icd_9 <= 289:
            return 'Disease of blood/blood-forming organs'
        elif 290 <= icd_9 <= 319:
            return 'Mental Disorder'
        elif 320 <= icd_9 <= 289:
            return 'Nervous System Disease'
        elif 390 <= icd_9 <= 459:
            return 'Circulatory Disease'
        elif 460 <= icd_9 <= 519:
            return 'Respiratory Disease'
        elif 520 <= icd_9 <= 579:
            return 'Digestive System Disease'
        elif 580 <= icd_9 <= 629:
            return 'Genitourinary Disease'
        elif 630 <= icd_9 <= 679:
            return 'Complications of pregnancy, childbirth, or puerperium'
        elif 680 <= icd_9 <= 709:
            return 'Skin Diseases'
        elif 710 <= icd_9 <= 739:
            return 'Musculoskeletal/Connective Tissue Disease'
        elif 740 <= icd_9 <= 759:
            return 'Congenital Anomaly'
        elif 760 <= icd_9 <= 779:
            return 'Perinatal Conditions'
        elif 780 <= icd_9 <= 799:
            return 'Symptoms, signs, or ill-defined conditions'
        elif 800 <= icd_9 <= 999:
            return 'Injury or poisoning'
        else:
            return 'Other'

    except (IndexError, ValueError, TypeError):
            return 'Other'

for col in all3_diag:
    data[col] = data[col].apply(map_diagnoses)


#--------------Encode target and binary features----------------
# Encode readmitted (as previously discussed)
data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == '<30' else (2 if x == '>30' else 0))

# Encode diabetesMed and change
data['diabetesMed'] = data['diabetesMed'].map({'No': 0, 'Yes': 1})

data['change'] = data['change'].map({'No': 0, 'Yes': 1})


##---------- Make all object columns categorical ----------
obj_cols = data.select_dtypes(include='object').columns
data[obj_cols] = data[obj_cols].astype('category')

#----------------------------------------------Create LightGBM model-----------------------------------------------------------
#-------------Create X and y then split--------------------
X = data.drop(columns='readmitted')
y = data['readmitted']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#-------------------------------new----------------------
classes = np.unique(y_train)                                                                          # new
weights = compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train)

class_weight_dictionary = dict(zip(classes, weights))

cat_feats = list(X_train.select_dtypes(include = 'category').columns)
#--------------------LightGBM model------------------------
model = LGBMClassifier(learning_rate=0.03,
                       num_leaves=63, max_depth=-1,
                       feature_fraction=0.8,
                       bagging_fraction=0.8,
                       bagging_freq=1,
                       min_data_in_leaf=20,
                       n_estimators=1500,
                       objective='multiclass',
                       metric='multi_logloss',
                       random_state = 42,
                      class_weight = class_weight_dictionary               #new
)
model.fit(X_train, y_train,
          eval_set=[(X_val, y_val)],
          categorical_feature = cat_feats,                                        #new
          callbacks=[lgb.early_stopping(stopping_rounds=50,
                                        verbose=False)])
#--------------------Evaluate---------------------------
pred = model.predict(X_val)
acc  = accuracy_score(y_val, pred)
f1   = f1_score(y_val, pred, average='weighted')
print(f'Accuracy: {acc:.3%} | Weighted F1: {f1:.3f}')

confusion_matrix = confusion_matrix(y_val, pred)
print('Confusion Matrix:\n', confusion_matrix)

